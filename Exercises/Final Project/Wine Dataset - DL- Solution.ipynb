{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wines Points prediction "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Submission Date : 3.6.2023\n",
    "Task: Predict the wine score given the inputs\n",
    "Instructions:\n",
    " * Use logistic regression as benchmark model\n",
    " * Use sklearn pipeliens + cv + grid search with sklearn models (e.g. KNNs, RandomForest, etc.)\n",
    " * Compare all models on proper metric (your choice)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For DNN course project:\n",
    "* Use sklearn pipeliens with tensorflow models (w/wo embeddings, LSTMs, RNNs, Transformers etc.)\n",
    "* Compare all models on proper metric (your choice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys; sys.path.append('../')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we will try to predict the points a wine will get based on known characteristics (i.e. features, in the ML terminology). The mine point in this stage is to establish a simple, ideally super cost effective, basline.\n",
    "In the real world there is a tradeoff between complexity and perforamnce, and the DS job, among others, is to present a tradeoff tables of what performance is achivalbel at what complexity level. \n",
    "\n",
    "to which models with increased complexity and resource demands will be compared. Complexity should then be translated into cost. For example:\n",
    " * Compute cost \n",
    " * Maintenance cost\n",
    " * Serving costs (i.e. is new platform needed?) \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-2.9.0.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import cufflinks as cf; cf.go_offline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine_reviews = pd.read_csv(\"clean_wine_reviews_data.csv\")\n",
    "summary_df = pd.read_csv(\"summary_df.csv\")\n",
    "wine_reviews.shape\n",
    "\n",
    "wine_reviews['desc_len'] = wine_reviews.description.str.len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>country</th>\n",
       "      <th>description</th>\n",
       "      <th>designation</th>\n",
       "      <th>points</th>\n",
       "      <th>price</th>\n",
       "      <th>province</th>\n",
       "      <th>region_1</th>\n",
       "      <th>region_2</th>\n",
       "      <th>taster_name</th>\n",
       "      <th>taster_twitter_handle</th>\n",
       "      <th>title</th>\n",
       "      <th>variety</th>\n",
       "      <th>winery</th>\n",
       "      <th>year</th>\n",
       "      <th>wine_category</th>\n",
       "      <th>desc_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Italy</td>\n",
       "      <td>Aromas include tropical fruit broom brimstone ...</td>\n",
       "      <td>Vulkà Bianco</td>\n",
       "      <td>87</td>\n",
       "      <td>39.928286</td>\n",
       "      <td>Sicily &amp; Sardinia</td>\n",
       "      <td>Etna</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Kerin O’Keefe</td>\n",
       "      <td>@kerinokeefe</td>\n",
       "      <td>Nicosia 2013 Vulkà Bianco  (Etna)</td>\n",
       "      <td>White Blend</td>\n",
       "      <td>Nicosia</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>White</td>\n",
       "      <td>152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Portugal</td>\n",
       "      <td>This ripe fruity wine smooth still structured ...</td>\n",
       "      <td>Avidagos</td>\n",
       "      <td>87</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>Douro</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Roger Voss</td>\n",
       "      <td>@vossroger</td>\n",
       "      <td>Quinta dos Avidagos 2011 Avidagos Red (Douro)</td>\n",
       "      <td>Portuguese Red</td>\n",
       "      <td>Quinta dos Avidagos</td>\n",
       "      <td>2011.0</td>\n",
       "      <td>Red</td>\n",
       "      <td>160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>US</td>\n",
       "      <td>Tart snappy flavors lime flesh rind dominate S...</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>87</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>Oregon</td>\n",
       "      <td>Willamette Valley</td>\n",
       "      <td>Willamette Valley</td>\n",
       "      <td>Paul Gregutt</td>\n",
       "      <td>@paulgwine</td>\n",
       "      <td>Rainstorm 2013 Pinot Gris (Willamette Valley)</td>\n",
       "      <td>Pinot Gris</td>\n",
       "      <td>Rainstorm</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>White</td>\n",
       "      <td>149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>US</td>\n",
       "      <td>Pineapple rind lemon pith orange blossom start...</td>\n",
       "      <td>Reserve Late Harvest</td>\n",
       "      <td>87</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>Michigan</td>\n",
       "      <td>Lake Michigan Shore</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Alexander Peartree</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>St. Julian 2013 Reserve Late Harvest Riesling ...</td>\n",
       "      <td>Riesling</td>\n",
       "      <td>St. Julian</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>White</td>\n",
       "      <td>155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>US</td>\n",
       "      <td>Much like regular bottling 2012 comes across r...</td>\n",
       "      <td>Vintner's Reserve Wild Child Block</td>\n",
       "      <td>87</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>Oregon</td>\n",
       "      <td>Willamette Valley</td>\n",
       "      <td>Willamette Valley</td>\n",
       "      <td>Paul Gregutt</td>\n",
       "      <td>@paulgwine</td>\n",
       "      <td>Sweet Cheeks 2012 Vintner's Reserve Wild Child...</td>\n",
       "      <td>Pinot Noir</td>\n",
       "      <td>Sweet Cheeks</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>Red</td>\n",
       "      <td>185</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0   country                                        description  \\\n",
       "0           0     Italy  Aromas include tropical fruit broom brimstone ...   \n",
       "1           1  Portugal  This ripe fruity wine smooth still structured ...   \n",
       "2           2        US  Tart snappy flavors lime flesh rind dominate S...   \n",
       "3           3        US  Pineapple rind lemon pith orange blossom start...   \n",
       "4           4        US  Much like regular bottling 2012 comes across r...   \n",
       "\n",
       "                          designation  points      price           province  \\\n",
       "0                        Vulkà Bianco      87  39.928286  Sicily & Sardinia   \n",
       "1                            Avidagos      87  15.000000              Douro   \n",
       "2                             Unknown      87  14.000000             Oregon   \n",
       "3                Reserve Late Harvest      87  13.000000           Michigan   \n",
       "4  Vintner's Reserve Wild Child Block      87  65.000000             Oregon   \n",
       "\n",
       "              region_1           region_2         taster_name  \\\n",
       "0                 Etna            Unknown       Kerin O’Keefe   \n",
       "1              Unknown            Unknown          Roger Voss   \n",
       "2    Willamette Valley  Willamette Valley        Paul Gregutt   \n",
       "3  Lake Michigan Shore            Unknown  Alexander Peartree   \n",
       "4    Willamette Valley  Willamette Valley        Paul Gregutt   \n",
       "\n",
       "  taster_twitter_handle                                              title  \\\n",
       "0          @kerinokeefe                  Nicosia 2013 Vulkà Bianco  (Etna)   \n",
       "1            @vossroger      Quinta dos Avidagos 2011 Avidagos Red (Douro)   \n",
       "2           @paulgwine       Rainstorm 2013 Pinot Gris (Willamette Valley)   \n",
       "3               Unknown  St. Julian 2013 Reserve Late Harvest Riesling ...   \n",
       "4           @paulgwine   Sweet Cheeks 2012 Vintner's Reserve Wild Child...   \n",
       "\n",
       "          variety               winery    year wine_category  desc_len  \n",
       "0     White Blend              Nicosia  2013.0         White       152  \n",
       "1  Portuguese Red  Quinta dos Avidagos  2011.0           Red       160  \n",
       "2      Pinot Gris            Rainstorm  2013.0         White       149  \n",
       "3        Riesling           St. Julian  2013.0         White       155  \n",
       "4      Pinot Noir         Sweet Cheeks  2012.0           Red       185  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine_reviews.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import Input, Dense, Embedding, Concatenate, Flatten, TextVectorization, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.metrics import MeanSquaredError\n",
    "from tensorflow.keras.losses import MeanSquaredError\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.utils import to_categorical, plot_model, pad_sequences\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras import activations\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting Model 1, Parameters: {'desc_words': 1000, 'desc_len': 626, 'activation': 'relu', 'units layer 1': 8, 'units layer 2': 4}\n",
      "Evaluating Model 1, Parameters: {'desc_words': 1000, 'desc_len': 626, 'activation': 'relu', 'units layer 1': 8, 'units layer 2': 4}\n",
      "2624/2624 - 4s - loss: 3920.1030 - 4s/epoch - 2ms/step\n",
      "875/875 - 1s - loss: 3920.4141 - 1s/epoch - 2ms/step\n",
      "Fitting Model 1, Parameters: {'desc_words': 1000, 'desc_len': 626, 'activation': 'relu', 'units layer 1': 8, 'units layer 2': 8}\n",
      "Evaluating Model 1, Parameters: {'desc_words': 1000, 'desc_len': 626, 'activation': 'relu', 'units layer 1': 8, 'units layer 2': 8}\n",
      "2624/2624 - 4s - loss: 1434.7241 - 4s/epoch - 2ms/step\n",
      "875/875 - 1s - loss: 1435.3904 - 1s/epoch - 2ms/step\n",
      "Passing Parameters: {'desc_words': 1000, 'desc_len': 626, 'activation': 'relu', 'units layer 1': 8, 'units layer 2': 16}\n",
      "Passing Parameters: {'desc_words': 1000, 'desc_len': 626, 'activation': 'relu', 'units layer 1': 8, 'units layer 2': 32}\n",
      "Passing Parameters: {'desc_words': 1000, 'desc_len': 626, 'activation': 'relu', 'units layer 1': 8, 'units layer 2': 64}\n",
      "Fitting Model 1, Parameters: {'desc_words': 1000, 'desc_len': 626, 'activation': 'relu', 'units layer 1': 16, 'units layer 2': 4}\n",
      "Evaluating Model 1, Parameters: {'desc_words': 1000, 'desc_len': 626, 'activation': 'relu', 'units layer 1': 16, 'units layer 2': 4}\n",
      "2624/2624 - 5s - loss: 794.2374 - 5s/epoch - 2ms/step\n",
      "875/875 - 1s - loss: 794.7361 - 1s/epoch - 2ms/step\n",
      "Fitting Model 1, Parameters: {'desc_words': 1000, 'desc_len': 626, 'activation': 'relu', 'units layer 1': 16, 'units layer 2': 8}\n",
      "Evaluating Model 1, Parameters: {'desc_words': 1000, 'desc_len': 626, 'activation': 'relu', 'units layer 1': 16, 'units layer 2': 8}\n",
      "2624/2624 - 5s - loss: 1068.5568 - 5s/epoch - 2ms/step\n",
      "875/875 - 2s - loss: 1069.0422 - 2s/epoch - 2ms/step\n",
      "Fitting Model 1, Parameters: {'desc_words': 1000, 'desc_len': 626, 'activation': 'relu', 'units layer 1': 16, 'units layer 2': 16}\n",
      "Evaluating Model 1, Parameters: {'desc_words': 1000, 'desc_len': 626, 'activation': 'relu', 'units layer 1': 16, 'units layer 2': 16}\n",
      "2624/2624 - 4s - loss: 1195.9038 - 4s/epoch - 2ms/step\n",
      "875/875 - 1s - loss: 1196.5095 - 1s/epoch - 2ms/step\n",
      "Passing Parameters: {'desc_words': 1000, 'desc_len': 626, 'activation': 'relu', 'units layer 1': 16, 'units layer 2': 32}\n",
      "Passing Parameters: {'desc_words': 1000, 'desc_len': 626, 'activation': 'relu', 'units layer 1': 16, 'units layer 2': 64}\n",
      "Fitting Model 1, Parameters: {'desc_words': 1000, 'desc_len': 626, 'activation': 'relu', 'units layer 1': 32, 'units layer 2': 4}\n",
      "Evaluating Model 1, Parameters: {'desc_words': 1000, 'desc_len': 626, 'activation': 'relu', 'units layer 1': 32, 'units layer 2': 4}\n",
      "2624/2624 - 5s - loss: 1160.7494 - 5s/epoch - 2ms/step\n",
      "875/875 - 2s - loss: 1161.1333 - 2s/epoch - 2ms/step\n",
      "Fitting Model 1, Parameters: {'desc_words': 1000, 'desc_len': 626, 'activation': 'relu', 'units layer 1': 32, 'units layer 2': 8}\n",
      "Evaluating Model 1, Parameters: {'desc_words': 1000, 'desc_len': 626, 'activation': 'relu', 'units layer 1': 32, 'units layer 2': 8}\n",
      "2624/2624 - 5s - loss: 544.2765 - 5s/epoch - 2ms/step\n",
      "875/875 - 1s - loss: 544.6620 - 1s/epoch - 2ms/step\n",
      "Fitting Model 1, Parameters: {'desc_words': 1000, 'desc_len': 626, 'activation': 'relu', 'units layer 1': 32, 'units layer 2': 16}\n",
      "Evaluating Model 1, Parameters: {'desc_words': 1000, 'desc_len': 626, 'activation': 'relu', 'units layer 1': 32, 'units layer 2': 16}\n",
      "2624/2624 - 5s - loss: 1245.4436 - 5s/epoch - 2ms/step\n",
      "875/875 - 2s - loss: 1246.0179 - 2s/epoch - 2ms/step\n",
      "Fitting Model 1, Parameters: {'desc_words': 1000, 'desc_len': 626, 'activation': 'relu', 'units layer 1': 32, 'units layer 2': 32}\n",
      "Evaluating Model 1, Parameters: {'desc_words': 1000, 'desc_len': 626, 'activation': 'relu', 'units layer 1': 32, 'units layer 2': 32}\n",
      "2624/2624 - 5s - loss: 1616.6329 - 5s/epoch - 2ms/step\n",
      "875/875 - 2s - loss: 1617.0852 - 2s/epoch - 2ms/step\n",
      "Passing Parameters: {'desc_words': 1000, 'desc_len': 626, 'activation': 'relu', 'units layer 1': 32, 'units layer 2': 64}\n",
      "Fitting Model 1, Parameters: {'desc_words': 1000, 'desc_len': 626, 'activation': 'relu', 'units layer 1': 64, 'units layer 2': 4}\n",
      "Evaluating Model 1, Parameters: {'desc_words': 1000, 'desc_len': 626, 'activation': 'relu', 'units layer 1': 64, 'units layer 2': 4}\n",
      "2624/2624 - 6s - loss: 1176.9200 - 6s/epoch - 2ms/step\n",
      "875/875 - 2s - loss: 1177.0439 - 2s/epoch - 2ms/step\n",
      "Fitting Model 1, Parameters: {'desc_words': 1000, 'desc_len': 626, 'activation': 'relu', 'units layer 1': 64, 'units layer 2': 8}\n",
      "Evaluating Model 1, Parameters: {'desc_words': 1000, 'desc_len': 626, 'activation': 'relu', 'units layer 1': 64, 'units layer 2': 8}\n",
      "2624/2624 - 6s - loss: 1721.4093 - 6s/epoch - 2ms/step\n",
      "875/875 - 2s - loss: 1721.9309 - 2s/epoch - 2ms/step\n",
      "Fitting Model 1, Parameters: {'desc_words': 1000, 'desc_len': 626, 'activation': 'relu', 'units layer 1': 64, 'units layer 2': 16}\n",
      "Evaluating Model 1, Parameters: {'desc_words': 1000, 'desc_len': 626, 'activation': 'relu', 'units layer 1': 64, 'units layer 2': 16}\n",
      "2624/2624 - 6s - loss: 1375.0831 - 6s/epoch - 2ms/step\n",
      "875/875 - 2s - loss: 1375.5015 - 2s/epoch - 2ms/step\n",
      "Fitting Model 1, Parameters: {'desc_words': 1000, 'desc_len': 626, 'activation': 'relu', 'units layer 1': 64, 'units layer 2': 32}\n",
      "Evaluating Model 1, Parameters: {'desc_words': 1000, 'desc_len': 626, 'activation': 'relu', 'units layer 1': 64, 'units layer 2': 32}\n",
      "2624/2624 - 6s - loss: 1747.1685 - 6s/epoch - 2ms/step\n",
      "875/875 - 2s - loss: 1747.7733 - 2s/epoch - 2ms/step\n",
      "Fitting Model 1, Parameters: {'desc_words': 1000, 'desc_len': 626, 'activation': 'relu', 'units layer 1': 64, 'units layer 2': 64}\n",
      "Evaluating Model 1, Parameters: {'desc_words': 1000, 'desc_len': 626, 'activation': 'relu', 'units layer 1': 64, 'units layer 2': 64}\n",
      "2624/2624 - 6s - loss: 1716.7477 - 6s/epoch - 2ms/step\n",
      "875/875 - 2s - loss: 1717.3892 - 2s/epoch - 2ms/step\n",
      "Fitting Model 1, Parameters: {'desc_words': 1000, 'desc_len': 626, 'activation': 'relu', 'units layer 1': 128, 'units layer 2': 4}\n",
      "Evaluating Model 1, Parameters: {'desc_words': 1000, 'desc_len': 626, 'activation': 'relu', 'units layer 1': 128, 'units layer 2': 4}\n",
      "2624/2624 - 7s - loss: 907.6434 - 7s/epoch - 3ms/step\n",
      "875/875 - 2s - loss: 907.9134 - 2s/epoch - 3ms/step\n",
      "Fitting Model 1, Parameters: {'desc_words': 1000, 'desc_len': 626, 'activation': 'relu', 'units layer 1': 128, 'units layer 2': 8}\n",
      "Evaluating Model 1, Parameters: {'desc_words': 1000, 'desc_len': 626, 'activation': 'relu', 'units layer 1': 128, 'units layer 2': 8}\n",
      "2624/2624 - 7s - loss: 1270.2721 - 7s/epoch - 3ms/step\n",
      "875/875 - 2s - loss: 1270.3822 - 2s/epoch - 3ms/step\n",
      "Fitting Model 1, Parameters: {'desc_words': 1000, 'desc_len': 626, 'activation': 'relu', 'units layer 1': 128, 'units layer 2': 16}\n",
      "Evaluating Model 1, Parameters: {'desc_words': 1000, 'desc_len': 626, 'activation': 'relu', 'units layer 1': 128, 'units layer 2': 16}\n",
      "2624/2624 - 7s - loss: 1797.9261 - 7s/epoch - 3ms/step\n",
      "875/875 - 2s - loss: 1798.2678 - 2s/epoch - 2ms/step\n",
      "Fitting Model 1, Parameters: {'desc_words': 1000, 'desc_len': 626, 'activation': 'relu', 'units layer 1': 128, 'units layer 2': 32}\n",
      "Evaluating Model 1, Parameters: {'desc_words': 1000, 'desc_len': 626, 'activation': 'relu', 'units layer 1': 128, 'units layer 2': 32}\n",
      "2624/2624 - 7s - loss: 1827.8706 - 7s/epoch - 3ms/step\n",
      "875/875 - 2s - loss: 1828.4185 - 2s/epoch - 2ms/step\n",
      "Fitting Model 1, Parameters: {'desc_words': 1000, 'desc_len': 626, 'activation': 'relu', 'units layer 1': 128, 'units layer 2': 64}\n",
      "Evaluating Model 1, Parameters: {'desc_words': 1000, 'desc_len': 626, 'activation': 'relu', 'units layer 1': 128, 'units layer 2': 64}\n",
      "2624/2624 - 6s - loss: 1890.2986 - 6s/epoch - 2ms/step\n",
      "875/875 - 2s - loss: 1890.6895 - 2s/epoch - 3ms/step\n",
      "Fitting Model 1, Parameters: {'desc_words': 1000, 'desc_len': 626, 'activation': 'sigmoid', 'units layer 1': 8, 'units layer 2': 4}\n",
      "Evaluating Model 1, Parameters: {'desc_words': 1000, 'desc_len': 626, 'activation': 'sigmoid', 'units layer 1': 8, 'units layer 2': 4}\n",
      "2624/2624 - 4s - loss: 9.1735 - 4s/epoch - 2ms/step\n",
      "875/875 - 1s - loss: 9.2699 - 1s/epoch - 2ms/step\n",
      "Fitting Model 1, Parameters: {'desc_words': 1000, 'desc_len': 626, 'activation': 'sigmoid', 'units layer 1': 8, 'units layer 2': 8}\n",
      "Evaluating Model 1, Parameters: {'desc_words': 1000, 'desc_len': 626, 'activation': 'sigmoid', 'units layer 1': 8, 'units layer 2': 8}\n",
      "2624/2624 - 5s - loss: 9.1748 - 5s/epoch - 2ms/step\n",
      "875/875 - 2s - loss: 9.2713 - 2s/epoch - 2ms/step\n",
      "Passing Parameters: {'desc_words': 1000, 'desc_len': 626, 'activation': 'sigmoid', 'units layer 1': 8, 'units layer 2': 16}\n",
      "Passing Parameters: {'desc_words': 1000, 'desc_len': 626, 'activation': 'sigmoid', 'units layer 1': 8, 'units layer 2': 32}\n",
      "Passing Parameters: {'desc_words': 1000, 'desc_len': 626, 'activation': 'sigmoid', 'units layer 1': 8, 'units layer 2': 64}\n",
      "Fitting Model 1, Parameters: {'desc_words': 1000, 'desc_len': 626, 'activation': 'sigmoid', 'units layer 1': 16, 'units layer 2': 4}\n",
      "Evaluating Model 1, Parameters: {'desc_words': 1000, 'desc_len': 626, 'activation': 'sigmoid', 'units layer 1': 16, 'units layer 2': 4}\n",
      "2624/2624 - 4s - loss: 9.1732 - 4s/epoch - 2ms/step\n",
      "875/875 - 2s - loss: 9.2697 - 2s/epoch - 2ms/step\n",
      "Fitting Model 1, Parameters: {'desc_words': 1000, 'desc_len': 626, 'activation': 'sigmoid', 'units layer 1': 16, 'units layer 2': 8}\n",
      "Evaluating Model 1, Parameters: {'desc_words': 1000, 'desc_len': 626, 'activation': 'sigmoid', 'units layer 1': 16, 'units layer 2': 8}\n",
      "2624/2624 - 4s - loss: 9.1780 - 4s/epoch - 2ms/step\n",
      "875/875 - 2s - loss: 9.2741 - 2s/epoch - 2ms/step\n",
      "Fitting Model 1, Parameters: {'desc_words': 1000, 'desc_len': 626, 'activation': 'sigmoid', 'units layer 1': 16, 'units layer 2': 16}\n",
      "Evaluating Model 1, Parameters: {'desc_words': 1000, 'desc_len': 626, 'activation': 'sigmoid', 'units layer 1': 16, 'units layer 2': 16}\n",
      "2624/2624 - 4s - loss: 9.1794 - 4s/epoch - 2ms/step\n",
      "875/875 - 1s - loss: 9.2755 - 1s/epoch - 2ms/step\n",
      "Passing Parameters: {'desc_words': 1000, 'desc_len': 626, 'activation': 'sigmoid', 'units layer 1': 16, 'units layer 2': 32}\n",
      "Passing Parameters: {'desc_words': 1000, 'desc_len': 626, 'activation': 'sigmoid', 'units layer 1': 16, 'units layer 2': 64}\n",
      "Fitting Model 1, Parameters: {'desc_words': 1000, 'desc_len': 626, 'activation': 'sigmoid', 'units layer 1': 32, 'units layer 2': 4}\n",
      "Evaluating Model 1, Parameters: {'desc_words': 1000, 'desc_len': 626, 'activation': 'sigmoid', 'units layer 1': 32, 'units layer 2': 4}\n",
      "2624/2624 - 6s - loss: 9.1792 - 6s/epoch - 2ms/step\n",
      "875/875 - 2s - loss: 9.2753 - 2s/epoch - 2ms/step\n",
      "Fitting Model 1, Parameters: {'desc_words': 1000, 'desc_len': 626, 'activation': 'sigmoid', 'units layer 1': 32, 'units layer 2': 8}\n",
      "Evaluating Model 1, Parameters: {'desc_words': 1000, 'desc_len': 626, 'activation': 'sigmoid', 'units layer 1': 32, 'units layer 2': 8}\n",
      "2624/2624 - 6s - loss: 9.1734 - 6s/epoch - 2ms/step\n",
      "875/875 - 2s - loss: 9.2699 - 2s/epoch - 2ms/step\n",
      "Fitting Model 1, Parameters: {'desc_words': 1000, 'desc_len': 626, 'activation': 'sigmoid', 'units layer 1': 32, 'units layer 2': 16}\n",
      "Evaluating Model 1, Parameters: {'desc_words': 1000, 'desc_len': 626, 'activation': 'sigmoid', 'units layer 1': 32, 'units layer 2': 16}\n",
      "2624/2624 - 5s - loss: 9.1833 - 5s/epoch - 2ms/step\n",
      "875/875 - 2s - loss: 9.2800 - 2s/epoch - 2ms/step\n",
      "Fitting Model 1, Parameters: {'desc_words': 1000, 'desc_len': 626, 'activation': 'sigmoid', 'units layer 1': 32, 'units layer 2': 32}\n",
      "Evaluating Model 1, Parameters: {'desc_words': 1000, 'desc_len': 626, 'activation': 'sigmoid', 'units layer 1': 32, 'units layer 2': 32}\n",
      "2624/2624 - 5s - loss: 2.9759 - 5s/epoch - 2ms/step\n",
      "875/875 - 2s - loss: 3.2773 - 2s/epoch - 2ms/step\n",
      "Passing Parameters: {'desc_words': 1000, 'desc_len': 626, 'activation': 'sigmoid', 'units layer 1': 32, 'units layer 2': 64}\n",
      "Fitting Model 1, Parameters: {'desc_words': 1000, 'desc_len': 626, 'activation': 'sigmoid', 'units layer 1': 64, 'units layer 2': 4}\n",
      "Evaluating Model 1, Parameters: {'desc_words': 1000, 'desc_len': 626, 'activation': 'sigmoid', 'units layer 1': 64, 'units layer 2': 4}\n",
      "2624/2624 - 6s - loss: 114.3933 - 6s/epoch - 2ms/step\n",
      "875/875 - 2s - loss: 114.5252 - 2s/epoch - 2ms/step\n",
      "Fitting Model 1, Parameters: {'desc_words': 1000, 'desc_len': 626, 'activation': 'sigmoid', 'units layer 1': 64, 'units layer 2': 8}\n",
      "Evaluating Model 1, Parameters: {'desc_words': 1000, 'desc_len': 626, 'activation': 'sigmoid', 'units layer 1': 64, 'units layer 2': 8}\n",
      "2624/2624 - 6s - loss: 9.1756 - 6s/epoch - 2ms/step\n",
      "875/875 - 2s - loss: 9.2722 - 2s/epoch - 2ms/step\n",
      "Fitting Model 1, Parameters: {'desc_words': 1000, 'desc_len': 626, 'activation': 'sigmoid', 'units layer 1': 64, 'units layer 2': 16}\n",
      "Evaluating Model 1, Parameters: {'desc_words': 1000, 'desc_len': 626, 'activation': 'sigmoid', 'units layer 1': 64, 'units layer 2': 16}\n",
      "2624/2624 - 6s - loss: 9.1791 - 6s/epoch - 2ms/step\n",
      "875/875 - 2s - loss: 9.2758 - 2s/epoch - 2ms/step\n",
      "Fitting Model 1, Parameters: {'desc_words': 1000, 'desc_len': 626, 'activation': 'sigmoid', 'units layer 1': 64, 'units layer 2': 32}\n",
      "Evaluating Model 1, Parameters: {'desc_words': 1000, 'desc_len': 626, 'activation': 'sigmoid', 'units layer 1': 64, 'units layer 2': 32}\n",
      "2624/2624 - 6s - loss: 3.1088 - 6s/epoch - 2ms/step\n",
      "875/875 - 2s - loss: 3.3137 - 2s/epoch - 2ms/step\n",
      "Fitting Model 1, Parameters: {'desc_words': 1000, 'desc_len': 626, 'activation': 'sigmoid', 'units layer 1': 64, 'units layer 2': 64}\n",
      "Evaluating Model 1, Parameters: {'desc_words': 1000, 'desc_len': 626, 'activation': 'sigmoid', 'units layer 1': 64, 'units layer 2': 64}\n",
      "2624/2624 - 6s - loss: 9.1840 - 6s/epoch - 2ms/step\n",
      "875/875 - 2s - loss: 9.2801 - 2s/epoch - 2ms/step\n",
      "Fitting Model 1, Parameters: {'desc_words': 1000, 'desc_len': 626, 'activation': 'sigmoid', 'units layer 1': 128, 'units layer 2': 4}\n",
      "Evaluating Model 1, Parameters: {'desc_words': 1000, 'desc_len': 626, 'activation': 'sigmoid', 'units layer 1': 128, 'units layer 2': 4}\n",
      "2624/2624 - 9s - loss: 215.1145 - 9s/epoch - 3ms/step\n",
      "875/875 - 6s - loss: 215.2605 - 6s/epoch - 7ms/step\n",
      "Fitting Model 1, Parameters: {'desc_words': 1000, 'desc_len': 626, 'activation': 'sigmoid', 'units layer 1': 128, 'units layer 2': 8}\n",
      "Evaluating Model 1, Parameters: {'desc_words': 1000, 'desc_len': 626, 'activation': 'sigmoid', 'units layer 1': 128, 'units layer 2': 8}\n",
      "2624/2624 - 16s - loss: 9.1759 - 16s/epoch - 6ms/step\n",
      "875/875 - 4s - loss: 9.2725 - 4s/epoch - 5ms/step\n",
      "Fitting Model 1, Parameters: {'desc_words': 1000, 'desc_len': 626, 'activation': 'sigmoid', 'units layer 1': 128, 'units layer 2': 16}\n",
      "Evaluating Model 1, Parameters: {'desc_words': 1000, 'desc_len': 626, 'activation': 'sigmoid', 'units layer 1': 128, 'units layer 2': 16}\n",
      "2624/2624 - 15s - loss: 3.1989 - 15s/epoch - 6ms/step\n",
      "875/875 - 5s - loss: 3.3974 - 5s/epoch - 5ms/step\n",
      "Fitting Model 1, Parameters: {'desc_words': 1000, 'desc_len': 626, 'activation': 'sigmoid', 'units layer 1': 128, 'units layer 2': 32}\n",
      "Evaluating Model 1, Parameters: {'desc_words': 1000, 'desc_len': 626, 'activation': 'sigmoid', 'units layer 1': 128, 'units layer 2': 32}\n",
      "2624/2624 - 14s - loss: 9.1742 - 14s/epoch - 5ms/step\n",
      "875/875 - 5s - loss: 9.2706 - 5s/epoch - 6ms/step\n",
      "Fitting Model 1, Parameters: {'desc_words': 1000, 'desc_len': 626, 'activation': 'sigmoid', 'units layer 1': 128, 'units layer 2': 64}\n",
      "Evaluating Model 1, Parameters: {'desc_words': 1000, 'desc_len': 626, 'activation': 'sigmoid', 'units layer 1': 128, 'units layer 2': 64}\n",
      "2624/2624 - 14s - loss: 9.2015 - 14s/epoch - 5ms/step\n",
      "875/875 - 4s - loss: 9.2985 - 4s/epoch - 5ms/step\n",
      "Fitting Model 1, Parameters: {'desc_words': 1000, 'desc_len': 60, 'activation': 'relu', 'units layer 1': 8, 'units layer 2': 4}\n",
      "Evaluating Model 1, Parameters: {'desc_words': 1000, 'desc_len': 60, 'activation': 'relu', 'units layer 1': 8, 'units layer 2': 4}\n",
      "2624/2624 - 3s - loss: 1203.0024 - 3s/epoch - 1ms/step\n",
      "875/875 - 1s - loss: 1203.5544 - 1s/epoch - 1ms/step\n",
      "Fitting Model 1, Parameters: {'desc_words': 1000, 'desc_len': 60, 'activation': 'relu', 'units layer 1': 8, 'units layer 2': 8}\n",
      "Evaluating Model 1, Parameters: {'desc_words': 1000, 'desc_len': 60, 'activation': 'relu', 'units layer 1': 8, 'units layer 2': 8}\n",
      "2624/2624 - 3s - loss: 823.3359 - 3s/epoch - 1ms/step\n",
      "875/875 - 1s - loss: 823.7498 - 1s/epoch - 1ms/step\n",
      "Passing Parameters: {'desc_words': 1000, 'desc_len': 60, 'activation': 'relu', 'units layer 1': 8, 'units layer 2': 16}\n",
      "Passing Parameters: {'desc_words': 1000, 'desc_len': 60, 'activation': 'relu', 'units layer 1': 8, 'units layer 2': 32}\n",
      "Passing Parameters: {'desc_words': 1000, 'desc_len': 60, 'activation': 'relu', 'units layer 1': 8, 'units layer 2': 64}\n",
      "Fitting Model 1, Parameters: {'desc_words': 1000, 'desc_len': 60, 'activation': 'relu', 'units layer 1': 16, 'units layer 2': 4}\n",
      "Evaluating Model 1, Parameters: {'desc_words': 1000, 'desc_len': 60, 'activation': 'relu', 'units layer 1': 16, 'units layer 2': 4}\n",
      "2624/2624 - 3s - loss: 716.9431 - 3s/epoch - 1ms/step\n",
      "875/875 - 1s - loss: 717.3441 - 1s/epoch - 1ms/step\n",
      "Fitting Model 1, Parameters: {'desc_words': 1000, 'desc_len': 60, 'activation': 'relu', 'units layer 1': 16, 'units layer 2': 8}\n",
      "Evaluating Model 1, Parameters: {'desc_words': 1000, 'desc_len': 60, 'activation': 'relu', 'units layer 1': 16, 'units layer 2': 8}\n",
      "2624/2624 - 4s - loss: 1880.8828 - 4s/epoch - 2ms/step\n",
      "875/875 - 1s - loss: 1881.2909 - 1s/epoch - 2ms/step\n",
      "Fitting Model 1, Parameters: {'desc_words': 1000, 'desc_len': 60, 'activation': 'relu', 'units layer 1': 16, 'units layer 2': 16}\n",
      "Evaluating Model 1, Parameters: {'desc_words': 1000, 'desc_len': 60, 'activation': 'relu', 'units layer 1': 16, 'units layer 2': 16}\n",
      "2624/2624 - 3s - loss: 1241.6752 - 3s/epoch - 1ms/step\n",
      "875/875 - 1s - loss: 1242.0933 - 1s/epoch - 1ms/step\n",
      "Passing Parameters: {'desc_words': 1000, 'desc_len': 60, 'activation': 'relu', 'units layer 1': 16, 'units layer 2': 32}\n",
      "Passing Parameters: {'desc_words': 1000, 'desc_len': 60, 'activation': 'relu', 'units layer 1': 16, 'units layer 2': 64}\n",
      "Fitting Model 1, Parameters: {'desc_words': 1000, 'desc_len': 60, 'activation': 'relu', 'units layer 1': 32, 'units layer 2': 4}\n",
      "Evaluating Model 1, Parameters: {'desc_words': 1000, 'desc_len': 60, 'activation': 'relu', 'units layer 1': 32, 'units layer 2': 4}\n",
      "2624/2624 - 4s - loss: 2.9195 - 4s/epoch - 2ms/step\n",
      "875/875 - 1s - loss: 3.3775 - 1s/epoch - 2ms/step\n",
      "Fitting Model 1, Parameters: {'desc_words': 1000, 'desc_len': 60, 'activation': 'relu', 'units layer 1': 32, 'units layer 2': 8}\n",
      "Evaluating Model 1, Parameters: {'desc_words': 1000, 'desc_len': 60, 'activation': 'relu', 'units layer 1': 32, 'units layer 2': 8}\n",
      "2624/2624 - 4s - loss: 1617.4528 - 4s/epoch - 2ms/step\n",
      "875/875 - 1s - loss: 1618.1633 - 1s/epoch - 1ms/step\n",
      "Fitting Model 1, Parameters: {'desc_words': 1000, 'desc_len': 60, 'activation': 'relu', 'units layer 1': 32, 'units layer 2': 16}\n",
      "Evaluating Model 1, Parameters: {'desc_words': 1000, 'desc_len': 60, 'activation': 'relu', 'units layer 1': 32, 'units layer 2': 16}\n",
      "2624/2624 - 4s - loss: 1889.3015 - 4s/epoch - 1ms/step\n",
      "875/875 - 1s - loss: 1889.7096 - 1s/epoch - 1ms/step\n",
      "Fitting Model 1, Parameters: {'desc_words': 1000, 'desc_len': 60, 'activation': 'relu', 'units layer 1': 32, 'units layer 2': 32}\n",
      "Evaluating Model 1, Parameters: {'desc_words': 1000, 'desc_len': 60, 'activation': 'relu', 'units layer 1': 32, 'units layer 2': 32}\n",
      "2624/2624 - 4s - loss: 1459.0223 - 4s/epoch - 1ms/step\n",
      "875/875 - 1s - loss: 1459.5629 - 1s/epoch - 1ms/step\n",
      "Passing Parameters: {'desc_words': 1000, 'desc_len': 60, 'activation': 'relu', 'units layer 1': 32, 'units layer 2': 64}\n",
      "Fitting Model 1, Parameters: {'desc_words': 1000, 'desc_len': 60, 'activation': 'relu', 'units layer 1': 64, 'units layer 2': 4}\n",
      "Evaluating Model 1, Parameters: {'desc_words': 1000, 'desc_len': 60, 'activation': 'relu', 'units layer 1': 64, 'units layer 2': 4}\n",
      "2624/2624 - 4s - loss: 7.7482 - 4s/epoch - 2ms/step\n",
      "875/875 - 2s - loss: 7.9218 - 2s/epoch - 2ms/step\n",
      "Fitting Model 1, Parameters: {'desc_words': 1000, 'desc_len': 60, 'activation': 'relu', 'units layer 1': 64, 'units layer 2': 8}\n",
      "Evaluating Model 1, Parameters: {'desc_words': 1000, 'desc_len': 60, 'activation': 'relu', 'units layer 1': 64, 'units layer 2': 8}\n",
      "2624/2624 - 4s - loss: 8.7332 - 4s/epoch - 2ms/step\n",
      "875/875 - 2s - loss: 8.8840 - 2s/epoch - 2ms/step\n",
      "Fitting Model 1, Parameters: {'desc_words': 1000, 'desc_len': 60, 'activation': 'relu', 'units layer 1': 64, 'units layer 2': 16}\n",
      "Evaluating Model 1, Parameters: {'desc_words': 1000, 'desc_len': 60, 'activation': 'relu', 'units layer 1': 64, 'units layer 2': 16}\n",
      "2624/2624 - 4s - loss: 931.2863 - 4s/epoch - 2ms/step\n",
      "875/875 - 2s - loss: 931.7635 - 2s/epoch - 2ms/step\n",
      "Fitting Model 1, Parameters: {'desc_words': 1000, 'desc_len': 60, 'activation': 'relu', 'units layer 1': 64, 'units layer 2': 32}\n",
      "Evaluating Model 1, Parameters: {'desc_words': 1000, 'desc_len': 60, 'activation': 'relu', 'units layer 1': 64, 'units layer 2': 32}\n",
      "2624/2624 - 4s - loss: 1504.4470 - 4s/epoch - 2ms/step\n",
      "875/875 - 2s - loss: 1504.8921 - 2s/epoch - 2ms/step\n",
      "Fitting Model 1, Parameters: {'desc_words': 1000, 'desc_len': 60, 'activation': 'relu', 'units layer 1': 64, 'units layer 2': 64}\n",
      "Evaluating Model 1, Parameters: {'desc_words': 1000, 'desc_len': 60, 'activation': 'relu', 'units layer 1': 64, 'units layer 2': 64}\n",
      "2624/2624 - 5s - loss: 851.9370 - 5s/epoch - 2ms/step\n",
      "875/875 - 1s - loss: 852.4502 - 1s/epoch - 2ms/step\n",
      "Fitting Model 1, Parameters: {'desc_words': 1000, 'desc_len': 60, 'activation': 'relu', 'units layer 1': 128, 'units layer 2': 4}\n",
      "Evaluating Model 1, Parameters: {'desc_words': 1000, 'desc_len': 60, 'activation': 'relu', 'units layer 1': 128, 'units layer 2': 4}\n",
      "2624/2624 - 5s - loss: 375.3934 - 5s/epoch - 2ms/step\n",
      "875/875 - 1s - loss: 375.4504 - 1s/epoch - 2ms/step\n",
      "Fitting Model 1, Parameters: {'desc_words': 1000, 'desc_len': 60, 'activation': 'relu', 'units layer 1': 128, 'units layer 2': 8}\n",
      "Evaluating Model 1, Parameters: {'desc_words': 1000, 'desc_len': 60, 'activation': 'relu', 'units layer 1': 128, 'units layer 2': 8}\n",
      "2624/2624 - 5s - loss: 284.5070 - 5s/epoch - 2ms/step\n",
      "875/875 - 2s - loss: 284.7483 - 2s/epoch - 2ms/step\n",
      "Fitting Model 1, Parameters: {'desc_words': 1000, 'desc_len': 60, 'activation': 'relu', 'units layer 1': 128, 'units layer 2': 16}\n",
      "Evaluating Model 1, Parameters: {'desc_words': 1000, 'desc_len': 60, 'activation': 'relu', 'units layer 1': 128, 'units layer 2': 16}\n",
      "2624/2624 - 4s - loss: 2.8965 - 4s/epoch - 2ms/step\n",
      "875/875 - 2s - loss: 3.4035 - 2s/epoch - 2ms/step\n",
      "Fitting Model 1, Parameters: {'desc_words': 1000, 'desc_len': 60, 'activation': 'relu', 'units layer 1': 128, 'units layer 2': 32}\n",
      "Evaluating Model 1, Parameters: {'desc_words': 1000, 'desc_len': 60, 'activation': 'relu', 'units layer 1': 128, 'units layer 2': 32}\n",
      "2624/2624 - 4s - loss: 45.7025 - 4s/epoch - 2ms/step\n",
      "875/875 - 2s - loss: 45.9252 - 2s/epoch - 2ms/step\n",
      "Fitting Model 1, Parameters: {'desc_words': 1000, 'desc_len': 60, 'activation': 'relu', 'units layer 1': 128, 'units layer 2': 64}\n",
      "Evaluating Model 1, Parameters: {'desc_words': 1000, 'desc_len': 60, 'activation': 'relu', 'units layer 1': 128, 'units layer 2': 64}\n",
      "2624/2624 - 5s - loss: 1379.8877 - 5s/epoch - 2ms/step\n",
      "875/875 - 1s - loss: 1380.4137 - 1s/epoch - 2ms/step\n",
      "Fitting Model 1, Parameters: {'desc_words': 1000, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 8, 'units layer 2': 4}\n",
      "Evaluating Model 1, Parameters: {'desc_words': 1000, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 8, 'units layer 2': 4}\n",
      "2624/2624 - 3s - loss: 9.1739 - 3s/epoch - 1ms/step\n",
      "875/875 - 1s - loss: 9.2702 - 973ms/epoch - 1ms/step\n",
      "Fitting Model 1, Parameters: {'desc_words': 1000, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 8, 'units layer 2': 8}\n",
      "Evaluating Model 1, Parameters: {'desc_words': 1000, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 8, 'units layer 2': 8}\n",
      "2624/2624 - 3s - loss: 9.1745 - 3s/epoch - 1ms/step\n",
      "875/875 - 1s - loss: 9.2708 - 1s/epoch - 1ms/step\n",
      "Passing Parameters: {'desc_words': 1000, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 8, 'units layer 2': 16}\n",
      "Passing Parameters: {'desc_words': 1000, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 8, 'units layer 2': 32}\n",
      "Passing Parameters: {'desc_words': 1000, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 8, 'units layer 2': 64}\n",
      "Fitting Model 1, Parameters: {'desc_words': 1000, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 16, 'units layer 2': 4}\n",
      "Evaluating Model 1, Parameters: {'desc_words': 1000, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 16, 'units layer 2': 4}\n",
      "2624/2624 - 5s - loss: 9.1736 - 5s/epoch - 2ms/step\n",
      "875/875 - 1s - loss: 9.2699 - 1s/epoch - 1ms/step\n",
      "Fitting Model 1, Parameters: {'desc_words': 1000, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 16, 'units layer 2': 8}\n",
      "Evaluating Model 1, Parameters: {'desc_words': 1000, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 16, 'units layer 2': 8}\n",
      "2624/2624 - 4s - loss: 9.1797 - 4s/epoch - 1ms/step\n",
      "875/875 - 2s - loss: 9.2759 - 2s/epoch - 2ms/step\n",
      "Fitting Model 1, Parameters: {'desc_words': 1000, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 16, 'units layer 2': 16}\n",
      "Evaluating Model 1, Parameters: {'desc_words': 1000, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 16, 'units layer 2': 16}\n",
      "2624/2624 - 4s - loss: 9.1775 - 4s/epoch - 2ms/step\n",
      "875/875 - 1s - loss: 9.2736 - 1s/epoch - 1ms/step\n",
      "Passing Parameters: {'desc_words': 1000, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 16, 'units layer 2': 32}\n",
      "Passing Parameters: {'desc_words': 1000, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 16, 'units layer 2': 64}\n",
      "Fitting Model 1, Parameters: {'desc_words': 1000, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 32, 'units layer 2': 4}\n",
      "Evaluating Model 1, Parameters: {'desc_words': 1000, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 32, 'units layer 2': 4}\n",
      "2624/2624 - 5s - loss: 9.1733 - 5s/epoch - 2ms/step\n",
      "875/875 - 1s - loss: 9.2698 - 1s/epoch - 2ms/step\n",
      "Fitting Model 1, Parameters: {'desc_words': 1000, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 32, 'units layer 2': 8}\n",
      "Evaluating Model 1, Parameters: {'desc_words': 1000, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 32, 'units layer 2': 8}\n",
      "2624/2624 - 5s - loss: 3.1416 - 5s/epoch - 2ms/step\n",
      "875/875 - 1s - loss: 3.3477 - 1s/epoch - 2ms/step\n",
      "Fitting Model 1, Parameters: {'desc_words': 1000, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 32, 'units layer 2': 16}\n",
      "Evaluating Model 1, Parameters: {'desc_words': 1000, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 32, 'units layer 2': 16}\n",
      "2624/2624 - 5s - loss: 3.2119 - 5s/epoch - 2ms/step\n",
      "875/875 - 2s - loss: 3.3801 - 2s/epoch - 2ms/step\n",
      "Fitting Model 1, Parameters: {'desc_words': 1000, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 32, 'units layer 2': 32}\n",
      "Evaluating Model 1, Parameters: {'desc_words': 1000, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 32, 'units layer 2': 32}\n",
      "2624/2624 - 4s - loss: 9.1747 - 4s/epoch - 2ms/step\n",
      "875/875 - 1s - loss: 9.2712 - 1s/epoch - 2ms/step\n",
      "Passing Parameters: {'desc_words': 1000, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 32, 'units layer 2': 64}\n",
      "Fitting Model 1, Parameters: {'desc_words': 1000, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 64, 'units layer 2': 4}\n",
      "Evaluating Model 1, Parameters: {'desc_words': 1000, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 64, 'units layer 2': 4}\n",
      "2624/2624 - 5s - loss: 9.2405 - 5s/epoch - 2ms/step\n",
      "875/875 - 2s - loss: 9.3378 - 2s/epoch - 2ms/step\n",
      "Fitting Model 1, Parameters: {'desc_words': 1000, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 64, 'units layer 2': 8}\n",
      "Evaluating Model 1, Parameters: {'desc_words': 1000, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 64, 'units layer 2': 8}\n",
      "2624/2624 - 5s - loss: 9.1733 - 5s/epoch - 2ms/step\n",
      "875/875 - 2s - loss: 9.2697 - 2s/epoch - 2ms/step\n",
      "Fitting Model 1, Parameters: {'desc_words': 1000, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 64, 'units layer 2': 16}\n",
      "Evaluating Model 1, Parameters: {'desc_words': 1000, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 64, 'units layer 2': 16}\n",
      "2624/2624 - 5s - loss: 4.3107 - 5s/epoch - 2ms/step\n",
      "875/875 - 2s - loss: 4.4104 - 2s/epoch - 2ms/step\n",
      "Fitting Model 1, Parameters: {'desc_words': 1000, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 64, 'units layer 2': 32}\n",
      "Evaluating Model 1, Parameters: {'desc_words': 1000, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 64, 'units layer 2': 32}\n",
      "2624/2624 - 6s - loss: 9.1775 - 6s/epoch - 2ms/step\n",
      "875/875 - 2s - loss: 9.2737 - 2s/epoch - 2ms/step\n",
      "Fitting Model 1, Parameters: {'desc_words': 1000, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 64, 'units layer 2': 64}\n",
      "Evaluating Model 1, Parameters: {'desc_words': 1000, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 64, 'units layer 2': 64}\n",
      "2624/2624 - 5s - loss: 9.2336 - 5s/epoch - 2ms/step\n",
      "875/875 - 2s - loss: 9.3291 - 2s/epoch - 2ms/step\n",
      "Fitting Model 1, Parameters: {'desc_words': 1000, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 128, 'units layer 2': 4}\n",
      "Evaluating Model 1, Parameters: {'desc_words': 1000, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 128, 'units layer 2': 4}\n",
      "2624/2624 - 5s - loss: 3439.3442 - 5s/epoch - 2ms/step\n",
      "875/875 - 2s - loss: 3439.6455 - 2s/epoch - 2ms/step\n",
      "Fitting Model 1, Parameters: {'desc_words': 1000, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 128, 'units layer 2': 8}\n",
      "Evaluating Model 1, Parameters: {'desc_words': 1000, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 128, 'units layer 2': 8}\n",
      "2624/2624 - 5s - loss: 9.1733 - 5s/epoch - 2ms/step\n",
      "875/875 - 2s - loss: 9.2697 - 2s/epoch - 2ms/step\n",
      "Fitting Model 1, Parameters: {'desc_words': 1000, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 128, 'units layer 2': 16}\n",
      "Evaluating Model 1, Parameters: {'desc_words': 1000, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 128, 'units layer 2': 16}\n",
      "2624/2624 - 5s - loss: 3.2715 - 5s/epoch - 2ms/step\n",
      "875/875 - 2s - loss: 3.4199 - 2s/epoch - 2ms/step\n",
      "Fitting Model 1, Parameters: {'desc_words': 1000, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 128, 'units layer 2': 32}\n",
      "Evaluating Model 1, Parameters: {'desc_words': 1000, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 128, 'units layer 2': 32}\n",
      "2624/2624 - 5s - loss: 9.1743 - 5s/epoch - 2ms/step\n",
      "875/875 - 2s - loss: 9.2706 - 2s/epoch - 2ms/step\n",
      "Fitting Model 1, Parameters: {'desc_words': 1000, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 128, 'units layer 2': 64}\n",
      "Evaluating Model 1, Parameters: {'desc_words': 1000, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 128, 'units layer 2': 64}\n",
      "2624/2624 - 5s - loss: 9.2229 - 5s/epoch - 2ms/step\n",
      "875/875 - 2s - loss: 9.3185 - 2s/epoch - 2ms/step\n",
      "Fitting Model 1, Parameters: {'desc_words': 5000, 'desc_len': 626, 'activation': 'relu', 'units layer 1': 8, 'units layer 2': 4}\n",
      "Evaluating Model 1, Parameters: {'desc_words': 5000, 'desc_len': 626, 'activation': 'relu', 'units layer 1': 8, 'units layer 2': 4}\n",
      "2624/2624 - 9s - loss: 1102.6815 - 9s/epoch - 4ms/step\n",
      "875/875 - 4s - loss: 1103.6083 - 4s/epoch - 5ms/step\n",
      "Fitting Model 1, Parameters: {'desc_words': 5000, 'desc_len': 626, 'activation': 'relu', 'units layer 1': 8, 'units layer 2': 8}\n",
      "Evaluating Model 1, Parameters: {'desc_words': 5000, 'desc_len': 626, 'activation': 'relu', 'units layer 1': 8, 'units layer 2': 8}\n",
      "2624/2624 - 7s - loss: 9.1740 - 7s/epoch - 3ms/step\n",
      "875/875 - 2s - loss: 9.2706 - 2s/epoch - 2ms/step\n",
      "Passing Parameters: {'desc_words': 5000, 'desc_len': 626, 'activation': 'relu', 'units layer 1': 8, 'units layer 2': 16}\n",
      "Passing Parameters: {'desc_words': 5000, 'desc_len': 626, 'activation': 'relu', 'units layer 1': 8, 'units layer 2': 32}\n",
      "Passing Parameters: {'desc_words': 5000, 'desc_len': 626, 'activation': 'relu', 'units layer 1': 8, 'units layer 2': 64}\n",
      "Fitting Model 1, Parameters: {'desc_words': 5000, 'desc_len': 626, 'activation': 'relu', 'units layer 1': 16, 'units layer 2': 4}\n",
      "Evaluating Model 1, Parameters: {'desc_words': 5000, 'desc_len': 626, 'activation': 'relu', 'units layer 1': 16, 'units layer 2': 4}\n",
      "2624/2624 - 6s - loss: 256.7925 - 6s/epoch - 2ms/step\n",
      "875/875 - 2s - loss: 257.0373 - 2s/epoch - 2ms/step\n",
      "Fitting Model 1, Parameters: {'desc_words': 5000, 'desc_len': 626, 'activation': 'relu', 'units layer 1': 16, 'units layer 2': 8}\n",
      "Evaluating Model 1, Parameters: {'desc_words': 5000, 'desc_len': 626, 'activation': 'relu', 'units layer 1': 16, 'units layer 2': 8}\n",
      "2624/2624 - 5s - loss: 1629.2667 - 5s/epoch - 2ms/step\n",
      "875/875 - 2s - loss: 1630.2964 - 2s/epoch - 2ms/step\n",
      "Fitting Model 1, Parameters: {'desc_words': 5000, 'desc_len': 626, 'activation': 'relu', 'units layer 1': 16, 'units layer 2': 16}\n",
      "Evaluating Model 1, Parameters: {'desc_words': 5000, 'desc_len': 626, 'activation': 'relu', 'units layer 1': 16, 'units layer 2': 16}\n",
      "2624/2624 - 7s - loss: 942.3215 - 7s/epoch - 3ms/step\n",
      "875/875 - 3s - loss: 943.4494 - 3s/epoch - 3ms/step\n",
      "Passing Parameters: {'desc_words': 5000, 'desc_len': 626, 'activation': 'relu', 'units layer 1': 16, 'units layer 2': 32}\n",
      "Passing Parameters: {'desc_words': 5000, 'desc_len': 626, 'activation': 'relu', 'units layer 1': 16, 'units layer 2': 64}\n",
      "Fitting Model 1, Parameters: {'desc_words': 5000, 'desc_len': 626, 'activation': 'relu', 'units layer 1': 32, 'units layer 2': 4}\n",
      "Evaluating Model 1, Parameters: {'desc_words': 5000, 'desc_len': 626, 'activation': 'relu', 'units layer 1': 32, 'units layer 2': 4}\n",
      "2624/2624 - 7s - loss: 3.0358 - 7s/epoch - 3ms/step\n",
      "875/875 - 3s - loss: 3.6246 - 3s/epoch - 3ms/step\n",
      "Fitting Model 1, Parameters: {'desc_words': 5000, 'desc_len': 626, 'activation': 'relu', 'units layer 1': 32, 'units layer 2': 8}\n",
      "Evaluating Model 1, Parameters: {'desc_words': 5000, 'desc_len': 626, 'activation': 'relu', 'units layer 1': 32, 'units layer 2': 8}\n",
      "2624/2624 - 7s - loss: 3.3048 - 7s/epoch - 3ms/step\n",
      "875/875 - 3s - loss: 4.2900 - 3s/epoch - 3ms/step\n",
      "Fitting Model 1, Parameters: {'desc_words': 5000, 'desc_len': 626, 'activation': 'relu', 'units layer 1': 32, 'units layer 2': 16}\n",
      "Evaluating Model 1, Parameters: {'desc_words': 5000, 'desc_len': 626, 'activation': 'relu', 'units layer 1': 32, 'units layer 2': 16}\n",
      "2624/2624 - 7s - loss: 1552.8481 - 7s/epoch - 3ms/step\n",
      "875/875 - 3s - loss: 1553.6248 - 3s/epoch - 3ms/step\n",
      "Fitting Model 1, Parameters: {'desc_words': 5000, 'desc_len': 626, 'activation': 'relu', 'units layer 1': 32, 'units layer 2': 32}\n",
      "Evaluating Model 1, Parameters: {'desc_words': 5000, 'desc_len': 626, 'activation': 'relu', 'units layer 1': 32, 'units layer 2': 32}\n",
      "2624/2624 - 7s - loss: 1610.3573 - 7s/epoch - 3ms/step\n",
      "875/875 - 3s - loss: 1611.4185 - 3s/epoch - 3ms/step\n",
      "Passing Parameters: {'desc_words': 5000, 'desc_len': 626, 'activation': 'relu', 'units layer 1': 32, 'units layer 2': 64}\n",
      "Fitting Model 1, Parameters: {'desc_words': 5000, 'desc_len': 626, 'activation': 'relu', 'units layer 1': 64, 'units layer 2': 4}\n",
      "Evaluating Model 1, Parameters: {'desc_words': 5000, 'desc_len': 626, 'activation': 'relu', 'units layer 1': 64, 'units layer 2': 4}\n",
      "2624/2624 - 16s - loss: 282.8033 - 16s/epoch - 6ms/step\n",
      "875/875 - 7s - loss: 283.1772 - 7s/epoch - 8ms/step\n",
      "Fitting Model 1, Parameters: {'desc_words': 5000, 'desc_len': 626, 'activation': 'relu', 'units layer 1': 64, 'units layer 2': 8}\n",
      "Evaluating Model 1, Parameters: {'desc_words': 5000, 'desc_len': 626, 'activation': 'relu', 'units layer 1': 64, 'units layer 2': 8}\n",
      "2624/2624 - 14s - loss: 1701.3389 - 14s/epoch - 5ms/step\n",
      "875/875 - 4s - loss: 1701.8425 - 4s/epoch - 5ms/step\n",
      "Fitting Model 1, Parameters: {'desc_words': 5000, 'desc_len': 626, 'activation': 'relu', 'units layer 1': 64, 'units layer 2': 16}\n",
      "Evaluating Model 1, Parameters: {'desc_words': 5000, 'desc_len': 626, 'activation': 'relu', 'units layer 1': 64, 'units layer 2': 16}\n",
      "2624/2624 - 11s - loss: 1564.9205 - 11s/epoch - 4ms/step\n",
      "875/875 - 4s - loss: 1565.9519 - 4s/epoch - 4ms/step\n",
      "Fitting Model 1, Parameters: {'desc_words': 5000, 'desc_len': 626, 'activation': 'relu', 'units layer 1': 64, 'units layer 2': 32}\n",
      "Evaluating Model 1, Parameters: {'desc_words': 5000, 'desc_len': 626, 'activation': 'relu', 'units layer 1': 64, 'units layer 2': 32}\n",
      "2624/2624 - 13s - loss: 1762.6378 - 13s/epoch - 5ms/step\n",
      "875/875 - 4s - loss: 1763.2285 - 4s/epoch - 5ms/step\n",
      "Fitting Model 1, Parameters: {'desc_words': 5000, 'desc_len': 626, 'activation': 'relu', 'units layer 1': 64, 'units layer 2': 64}\n",
      "Evaluating Model 1, Parameters: {'desc_words': 5000, 'desc_len': 626, 'activation': 'relu', 'units layer 1': 64, 'units layer 2': 64}\n",
      "2624/2624 - 12s - loss: 1755.6465 - 12s/epoch - 5ms/step\n",
      "875/875 - 4s - loss: 1756.7915 - 4s/epoch - 5ms/step\n",
      "Fitting Model 1, Parameters: {'desc_words': 5000, 'desc_len': 626, 'activation': 'relu', 'units layer 1': 128, 'units layer 2': 4}\n",
      "Evaluating Model 1, Parameters: {'desc_words': 5000, 'desc_len': 626, 'activation': 'relu', 'units layer 1': 128, 'units layer 2': 4}\n",
      "2624/2624 - 15s - loss: 350.3645 - 15s/epoch - 6ms/step\n",
      "875/875 - 5s - loss: 350.9300 - 5s/epoch - 5ms/step\n",
      "Fitting Model 1, Parameters: {'desc_words': 5000, 'desc_len': 626, 'activation': 'relu', 'units layer 1': 128, 'units layer 2': 8}\n",
      "Evaluating Model 1, Parameters: {'desc_words': 5000, 'desc_len': 626, 'activation': 'relu', 'units layer 1': 128, 'units layer 2': 8}\n",
      "2624/2624 - 15s - loss: 1785.3424 - 15s/epoch - 6ms/step\n",
      "875/875 - 5s - loss: 1785.7307 - 5s/epoch - 5ms/step\n",
      "Fitting Model 1, Parameters: {'desc_words': 5000, 'desc_len': 626, 'activation': 'relu', 'units layer 1': 128, 'units layer 2': 16}\n",
      "Evaluating Model 1, Parameters: {'desc_words': 5000, 'desc_len': 626, 'activation': 'relu', 'units layer 1': 128, 'units layer 2': 16}\n",
      "2624/2624 - 15s - loss: 1776.9583 - 15s/epoch - 6ms/step\n",
      "875/875 - 6s - loss: 1777.4126 - 6s/epoch - 7ms/step\n",
      "Fitting Model 1, Parameters: {'desc_words': 5000, 'desc_len': 626, 'activation': 'relu', 'units layer 1': 128, 'units layer 2': 32}\n",
      "Evaluating Model 1, Parameters: {'desc_words': 5000, 'desc_len': 626, 'activation': 'relu', 'units layer 1': 128, 'units layer 2': 32}\n",
      "2624/2624 - 15s - loss: 2218.9307 - 15s/epoch - 6ms/step\n",
      "875/875 - 4s - loss: 2219.3486 - 4s/epoch - 5ms/step\n",
      "Fitting Model 1, Parameters: {'desc_words': 5000, 'desc_len': 626, 'activation': 'relu', 'units layer 1': 128, 'units layer 2': 64}\n",
      "Evaluating Model 1, Parameters: {'desc_words': 5000, 'desc_len': 626, 'activation': 'relu', 'units layer 1': 128, 'units layer 2': 64}\n",
      "2624/2624 - 14s - loss: 1800.3982 - 14s/epoch - 5ms/step\n",
      "875/875 - 5s - loss: 1801.3118 - 5s/epoch - 6ms/step\n",
      "Fitting Model 1, Parameters: {'desc_words': 5000, 'desc_len': 626, 'activation': 'sigmoid', 'units layer 1': 8, 'units layer 2': 4}\n",
      "Evaluating Model 1, Parameters: {'desc_words': 5000, 'desc_len': 626, 'activation': 'sigmoid', 'units layer 1': 8, 'units layer 2': 4}\n",
      "2624/2624 - 9s - loss: 9.1738 - 9s/epoch - 3ms/step\n",
      "875/875 - 2s - loss: 9.2701 - 2s/epoch - 3ms/step\n",
      "Fitting Model 1, Parameters: {'desc_words': 5000, 'desc_len': 626, 'activation': 'sigmoid', 'units layer 1': 8, 'units layer 2': 8}\n",
      "Evaluating Model 1, Parameters: {'desc_words': 5000, 'desc_len': 626, 'activation': 'sigmoid', 'units layer 1': 8, 'units layer 2': 8}\n",
      "2624/2624 - 8s - loss: 9.1779 - 8s/epoch - 3ms/step\n",
      "875/875 - 2s - loss: 9.2741 - 2s/epoch - 2ms/step\n",
      "Passing Parameters: {'desc_words': 5000, 'desc_len': 626, 'activation': 'sigmoid', 'units layer 1': 8, 'units layer 2': 16}\n",
      "Passing Parameters: {'desc_words': 5000, 'desc_len': 626, 'activation': 'sigmoid', 'units layer 1': 8, 'units layer 2': 32}\n",
      "Passing Parameters: {'desc_words': 5000, 'desc_len': 626, 'activation': 'sigmoid', 'units layer 1': 8, 'units layer 2': 64}\n",
      "Fitting Model 1, Parameters: {'desc_words': 5000, 'desc_len': 626, 'activation': 'sigmoid', 'units layer 1': 16, 'units layer 2': 4}\n",
      "Evaluating Model 1, Parameters: {'desc_words': 5000, 'desc_len': 626, 'activation': 'sigmoid', 'units layer 1': 16, 'units layer 2': 4}\n",
      "2624/2624 - 7s - loss: 9.1739 - 7s/epoch - 3ms/step\n",
      "875/875 - 3s - loss: 9.2703 - 3s/epoch - 3ms/step\n",
      "Fitting Model 1, Parameters: {'desc_words': 5000, 'desc_len': 626, 'activation': 'sigmoid', 'units layer 1': 16, 'units layer 2': 8}\n",
      "Evaluating Model 1, Parameters: {'desc_words': 5000, 'desc_len': 626, 'activation': 'sigmoid', 'units layer 1': 16, 'units layer 2': 8}\n",
      "2624/2624 - 8s - loss: 9.1735 - 8s/epoch - 3ms/step\n",
      "875/875 - 2s - loss: 9.2699 - 2s/epoch - 3ms/step\n",
      "Fitting Model 1, Parameters: {'desc_words': 5000, 'desc_len': 626, 'activation': 'sigmoid', 'units layer 1': 16, 'units layer 2': 16}\n",
      "Evaluating Model 1, Parameters: {'desc_words': 5000, 'desc_len': 626, 'activation': 'sigmoid', 'units layer 1': 16, 'units layer 2': 16}\n",
      "2624/2624 - 10s - loss: 9.1868 - 10s/epoch - 4ms/step\n",
      "875/875 - 2s - loss: 9.2828 - 2s/epoch - 2ms/step\n",
      "Passing Parameters: {'desc_words': 5000, 'desc_len': 626, 'activation': 'sigmoid', 'units layer 1': 16, 'units layer 2': 32}\n",
      "Passing Parameters: {'desc_words': 5000, 'desc_len': 626, 'activation': 'sigmoid', 'units layer 1': 16, 'units layer 2': 64}\n",
      "Fitting Model 1, Parameters: {'desc_words': 5000, 'desc_len': 626, 'activation': 'sigmoid', 'units layer 1': 32, 'units layer 2': 4}\n",
      "Evaluating Model 1, Parameters: {'desc_words': 5000, 'desc_len': 626, 'activation': 'sigmoid', 'units layer 1': 32, 'units layer 2': 4}\n",
      "2624/2624 - 9s - loss: 9.1757 - 9s/epoch - 4ms/step\n",
      "875/875 - 3s - loss: 9.2723 - 3s/epoch - 3ms/step\n",
      "Fitting Model 1, Parameters: {'desc_words': 5000, 'desc_len': 626, 'activation': 'sigmoid', 'units layer 1': 32, 'units layer 2': 8}\n",
      "Evaluating Model 1, Parameters: {'desc_words': 5000, 'desc_len': 626, 'activation': 'sigmoid', 'units layer 1': 32, 'units layer 2': 8}\n",
      "2624/2624 - 9s - loss: 9.1746 - 9s/epoch - 4ms/step\n",
      "875/875 - 4s - loss: 9.2709 - 4s/epoch - 4ms/step\n",
      "Fitting Model 1, Parameters: {'desc_words': 5000, 'desc_len': 626, 'activation': 'sigmoid', 'units layer 1': 32, 'units layer 2': 16}\n",
      "Evaluating Model 1, Parameters: {'desc_words': 5000, 'desc_len': 626, 'activation': 'sigmoid', 'units layer 1': 32, 'units layer 2': 16}\n",
      "2624/2624 - 11s - loss: 9.1734 - 11s/epoch - 4ms/step\n",
      "875/875 - 6s - loss: 9.2698 - 6s/epoch - 6ms/step\n",
      "Fitting Model 1, Parameters: {'desc_words': 5000, 'desc_len': 626, 'activation': 'sigmoid', 'units layer 1': 32, 'units layer 2': 32}\n",
      "Evaluating Model 1, Parameters: {'desc_words': 5000, 'desc_len': 626, 'activation': 'sigmoid', 'units layer 1': 32, 'units layer 2': 32}\n",
      "2624/2624 - 13s - loss: 2.0345 - 13s/epoch - 5ms/step\n",
      "875/875 - 3s - loss: 2.7004 - 3s/epoch - 4ms/step\n",
      "Passing Parameters: {'desc_words': 5000, 'desc_len': 626, 'activation': 'sigmoid', 'units layer 1': 32, 'units layer 2': 64}\n",
      "Fitting Model 1, Parameters: {'desc_words': 5000, 'desc_len': 626, 'activation': 'sigmoid', 'units layer 1': 64, 'units layer 2': 4}\n",
      "Evaluating Model 1, Parameters: {'desc_words': 5000, 'desc_len': 626, 'activation': 'sigmoid', 'units layer 1': 64, 'units layer 2': 4}\n",
      "2624/2624 - 15s - loss: 9.2318 - 15s/epoch - 6ms/step\n",
      "875/875 - 5s - loss: 9.3291 - 5s/epoch - 6ms/step\n",
      "Fitting Model 1, Parameters: {'desc_words': 5000, 'desc_len': 626, 'activation': 'sigmoid', 'units layer 1': 64, 'units layer 2': 8}\n",
      "Evaluating Model 1, Parameters: {'desc_words': 5000, 'desc_len': 626, 'activation': 'sigmoid', 'units layer 1': 64, 'units layer 2': 8}\n",
      "2624/2624 - 15s - loss: 9.1746 - 15s/epoch - 6ms/step\n",
      "875/875 - 3s - loss: 9.2712 - 3s/epoch - 4ms/step\n",
      "Fitting Model 1, Parameters: {'desc_words': 5000, 'desc_len': 626, 'activation': 'sigmoid', 'units layer 1': 64, 'units layer 2': 16}\n",
      "Evaluating Model 1, Parameters: {'desc_words': 5000, 'desc_len': 626, 'activation': 'sigmoid', 'units layer 1': 64, 'units layer 2': 16}\n",
      "2624/2624 - 15s - loss: 9.1798 - 15s/epoch - 6ms/step\n",
      "875/875 - 4s - loss: 9.2764 - 4s/epoch - 4ms/step\n",
      "Fitting Model 1, Parameters: {'desc_words': 5000, 'desc_len': 626, 'activation': 'sigmoid', 'units layer 1': 64, 'units layer 2': 32}\n",
      "Evaluating Model 1, Parameters: {'desc_words': 5000, 'desc_len': 626, 'activation': 'sigmoid', 'units layer 1': 64, 'units layer 2': 32}\n",
      "2624/2624 - 18s - loss: 9.1733 - 18s/epoch - 7ms/step\n",
      "875/875 - 4s - loss: 9.2697 - 4s/epoch - 4ms/step\n",
      "Fitting Model 1, Parameters: {'desc_words': 5000, 'desc_len': 626, 'activation': 'sigmoid', 'units layer 1': 64, 'units layer 2': 64}\n",
      "Evaluating Model 1, Parameters: {'desc_words': 5000, 'desc_len': 626, 'activation': 'sigmoid', 'units layer 1': 64, 'units layer 2': 64}\n",
      "2624/2624 - 17s - loss: 9.1951 - 17s/epoch - 6ms/step\n",
      "875/875 - 3s - loss: 9.2921 - 3s/epoch - 4ms/step\n",
      "Fitting Model 1, Parameters: {'desc_words': 5000, 'desc_len': 626, 'activation': 'sigmoid', 'units layer 1': 128, 'units layer 2': 4}\n",
      "Evaluating Model 1, Parameters: {'desc_words': 5000, 'desc_len': 626, 'activation': 'sigmoid', 'units layer 1': 128, 'units layer 2': 4}\n",
      "2624/2624 - 15s - loss: 215.6293 - 15s/epoch - 6ms/step\n",
      "875/875 - 5s - loss: 215.7752 - 5s/epoch - 6ms/step\n",
      "Fitting Model 1, Parameters: {'desc_words': 5000, 'desc_len': 626, 'activation': 'sigmoid', 'units layer 1': 128, 'units layer 2': 8}\n",
      "Evaluating Model 1, Parameters: {'desc_words': 5000, 'desc_len': 626, 'activation': 'sigmoid', 'units layer 1': 128, 'units layer 2': 8}\n",
      "2624/2624 - 32s - loss: 9.1736 - 32s/epoch - 12ms/step\n",
      "875/875 - 8s - loss: 9.2701 - 8s/epoch - 9ms/step\n",
      "Fitting Model 1, Parameters: {'desc_words': 5000, 'desc_len': 626, 'activation': 'sigmoid', 'units layer 1': 128, 'units layer 2': 16}\n",
      "Evaluating Model 1, Parameters: {'desc_words': 5000, 'desc_len': 626, 'activation': 'sigmoid', 'units layer 1': 128, 'units layer 2': 16}\n",
      "2624/2624 - 30s - loss: 9.1733 - 30s/epoch - 12ms/step\n",
      "875/875 - 11s - loss: 9.2697 - 11s/epoch - 12ms/step\n",
      "Fitting Model 1, Parameters: {'desc_words': 5000, 'desc_len': 626, 'activation': 'sigmoid', 'units layer 1': 128, 'units layer 2': 32}\n",
      "Evaluating Model 1, Parameters: {'desc_words': 5000, 'desc_len': 626, 'activation': 'sigmoid', 'units layer 1': 128, 'units layer 2': 32}\n",
      "2624/2624 - 29s - loss: 2.1151 - 29s/epoch - 11ms/step\n",
      "875/875 - 9s - loss: 2.6909 - 9s/epoch - 11ms/step\n",
      "Fitting Model 1, Parameters: {'desc_words': 5000, 'desc_len': 626, 'activation': 'sigmoid', 'units layer 1': 128, 'units layer 2': 64}\n",
      "Evaluating Model 1, Parameters: {'desc_words': 5000, 'desc_len': 626, 'activation': 'sigmoid', 'units layer 1': 128, 'units layer 2': 64}\n",
      "2624/2624 - 28s - loss: 2.1077 - 28s/epoch - 11ms/step\n",
      "875/875 - 9s - loss: 2.6569 - 9s/epoch - 10ms/step\n",
      "Fitting Model 1, Parameters: {'desc_words': 5000, 'desc_len': 60, 'activation': 'relu', 'units layer 1': 8, 'units layer 2': 4}\n",
      "Evaluating Model 1, Parameters: {'desc_words': 5000, 'desc_len': 60, 'activation': 'relu', 'units layer 1': 8, 'units layer 2': 4}\n",
      "2624/2624 - 5s - loss: 437.0185 - 5s/epoch - 2ms/step\n",
      "875/875 - 4s - loss: 437.4287 - 4s/epoch - 4ms/step\n",
      "Fitting Model 1, Parameters: {'desc_words': 5000, 'desc_len': 60, 'activation': 'relu', 'units layer 1': 8, 'units layer 2': 8}\n",
      "Evaluating Model 1, Parameters: {'desc_words': 5000, 'desc_len': 60, 'activation': 'relu', 'units layer 1': 8, 'units layer 2': 8}\n",
      "2624/2624 - 7s - loss: 1355.4749 - 7s/epoch - 3ms/step\n",
      "875/875 - 3s - loss: 1356.5176 - 3s/epoch - 4ms/step\n",
      "Passing Parameters: {'desc_words': 5000, 'desc_len': 60, 'activation': 'relu', 'units layer 1': 8, 'units layer 2': 16}\n",
      "Passing Parameters: {'desc_words': 5000, 'desc_len': 60, 'activation': 'relu', 'units layer 1': 8, 'units layer 2': 32}\n",
      "Passing Parameters: {'desc_words': 5000, 'desc_len': 60, 'activation': 'relu', 'units layer 1': 8, 'units layer 2': 64}\n",
      "Fitting Model 1, Parameters: {'desc_words': 5000, 'desc_len': 60, 'activation': 'relu', 'units layer 1': 16, 'units layer 2': 4}\n",
      "Evaluating Model 1, Parameters: {'desc_words': 5000, 'desc_len': 60, 'activation': 'relu', 'units layer 1': 16, 'units layer 2': 4}\n",
      "2624/2624 - 8s - loss: 1118.2495 - 8s/epoch - 3ms/step\n",
      "875/875 - 3s - loss: 1119.1200 - 3s/epoch - 3ms/step\n",
      "Fitting Model 1, Parameters: {'desc_words': 5000, 'desc_len': 60, 'activation': 'relu', 'units layer 1': 16, 'units layer 2': 8}\n",
      "Evaluating Model 1, Parameters: {'desc_words': 5000, 'desc_len': 60, 'activation': 'relu', 'units layer 1': 16, 'units layer 2': 8}\n",
      "2624/2624 - 6s - loss: 1349.9464 - 6s/epoch - 2ms/step\n",
      "875/875 - 2s - loss: 1350.7352 - 2s/epoch - 2ms/step\n",
      "Fitting Model 1, Parameters: {'desc_words': 5000, 'desc_len': 60, 'activation': 'relu', 'units layer 1': 16, 'units layer 2': 16}\n",
      "Evaluating Model 1, Parameters: {'desc_words': 5000, 'desc_len': 60, 'activation': 'relu', 'units layer 1': 16, 'units layer 2': 16}\n",
      "2624/2624 - 4s - loss: 1160.5500 - 4s/epoch - 2ms/step\n",
      "875/875 - 1s - loss: 1161.4960 - 1s/epoch - 2ms/step\n",
      "Passing Parameters: {'desc_words': 5000, 'desc_len': 60, 'activation': 'relu', 'units layer 1': 16, 'units layer 2': 32}\n",
      "Passing Parameters: {'desc_words': 5000, 'desc_len': 60, 'activation': 'relu', 'units layer 1': 16, 'units layer 2': 64}\n",
      "Fitting Model 1, Parameters: {'desc_words': 5000, 'desc_len': 60, 'activation': 'relu', 'units layer 1': 32, 'units layer 2': 4}\n",
      "Evaluating Model 1, Parameters: {'desc_words': 5000, 'desc_len': 60, 'activation': 'relu', 'units layer 1': 32, 'units layer 2': 4}\n",
      "2624/2624 - 4s - loss: 1078.6925 - 4s/epoch - 2ms/step\n",
      "875/875 - 1s - loss: 1079.2310 - 1s/epoch - 2ms/step\n",
      "Fitting Model 1, Parameters: {'desc_words': 5000, 'desc_len': 60, 'activation': 'relu', 'units layer 1': 32, 'units layer 2': 8}\n",
      "Evaluating Model 1, Parameters: {'desc_words': 5000, 'desc_len': 60, 'activation': 'relu', 'units layer 1': 32, 'units layer 2': 8}\n",
      "2624/2624 - 6s - loss: 1021.3055 - 6s/epoch - 2ms/step\n",
      "875/875 - 2s - loss: 1021.9026 - 2s/epoch - 2ms/step\n",
      "Fitting Model 1, Parameters: {'desc_words': 5000, 'desc_len': 60, 'activation': 'relu', 'units layer 1': 32, 'units layer 2': 16}\n",
      "Evaluating Model 1, Parameters: {'desc_words': 5000, 'desc_len': 60, 'activation': 'relu', 'units layer 1': 32, 'units layer 2': 16}\n",
      "2624/2624 - 4s - loss: 1191.7039 - 4s/epoch - 2ms/step\n",
      "875/875 - 1s - loss: 1192.6691 - 1s/epoch - 2ms/step\n",
      "Fitting Model 1, Parameters: {'desc_words': 5000, 'desc_len': 60, 'activation': 'relu', 'units layer 1': 32, 'units layer 2': 32}\n",
      "Evaluating Model 1, Parameters: {'desc_words': 5000, 'desc_len': 60, 'activation': 'relu', 'units layer 1': 32, 'units layer 2': 32}\n",
      "2624/2624 - 4s - loss: 1318.1003 - 4s/epoch - 2ms/step\n",
      "875/875 - 2s - loss: 1319.4291 - 2s/epoch - 2ms/step\n",
      "Passing Parameters: {'desc_words': 5000, 'desc_len': 60, 'activation': 'relu', 'units layer 1': 32, 'units layer 2': 64}\n",
      "Fitting Model 1, Parameters: {'desc_words': 5000, 'desc_len': 60, 'activation': 'relu', 'units layer 1': 64, 'units layer 2': 4}\n",
      "Evaluating Model 1, Parameters: {'desc_words': 5000, 'desc_len': 60, 'activation': 'relu', 'units layer 1': 64, 'units layer 2': 4}\n",
      "2624/2624 - 4s - loss: 2.1461 - 4s/epoch - 2ms/step\n",
      "875/875 - 1s - loss: 2.8059 - 1s/epoch - 2ms/step\n",
      "Fitting Model 1, Parameters: {'desc_words': 5000, 'desc_len': 60, 'activation': 'relu', 'units layer 1': 64, 'units layer 2': 8}\n",
      "Evaluating Model 1, Parameters: {'desc_words': 5000, 'desc_len': 60, 'activation': 'relu', 'units layer 1': 64, 'units layer 2': 8}\n",
      "2624/2624 - 5s - loss: 1011.3353 - 5s/epoch - 2ms/step\n",
      "875/875 - 2s - loss: 1011.8243 - 2s/epoch - 2ms/step\n",
      "Fitting Model 1, Parameters: {'desc_words': 5000, 'desc_len': 60, 'activation': 'relu', 'units layer 1': 64, 'units layer 2': 16}\n",
      "Evaluating Model 1, Parameters: {'desc_words': 5000, 'desc_len': 60, 'activation': 'relu', 'units layer 1': 64, 'units layer 2': 16}\n",
      "2624/2624 - 4s - loss: 980.0402 - 4s/epoch - 2ms/step\n",
      "875/875 - 2s - loss: 980.4605 - 2s/epoch - 2ms/step\n",
      "Fitting Model 1, Parameters: {'desc_words': 5000, 'desc_len': 60, 'activation': 'relu', 'units layer 1': 64, 'units layer 2': 32}\n",
      "Evaluating Model 1, Parameters: {'desc_words': 5000, 'desc_len': 60, 'activation': 'relu', 'units layer 1': 64, 'units layer 2': 32}\n",
      "2624/2624 - 4s - loss: 1267.9490 - 4s/epoch - 2ms/step\n",
      "875/875 - 3s - loss: 1268.8022 - 3s/epoch - 3ms/step\n",
      "Fitting Model 1, Parameters: {'desc_words': 5000, 'desc_len': 60, 'activation': 'relu', 'units layer 1': 64, 'units layer 2': 64}\n",
      "Evaluating Model 1, Parameters: {'desc_words': 5000, 'desc_len': 60, 'activation': 'relu', 'units layer 1': 64, 'units layer 2': 64}\n",
      "2624/2624 - 4s - loss: 1291.5145 - 4s/epoch - 2ms/step\n",
      "875/875 - 1s - loss: 1292.1090 - 1s/epoch - 2ms/step\n",
      "Fitting Model 1, Parameters: {'desc_words': 5000, 'desc_len': 60, 'activation': 'relu', 'units layer 1': 128, 'units layer 2': 4}\n",
      "Evaluating Model 1, Parameters: {'desc_words': 5000, 'desc_len': 60, 'activation': 'relu', 'units layer 1': 128, 'units layer 2': 4}\n",
      "2624/2624 - 5s - loss: 6.8021 - 5s/epoch - 2ms/step\n",
      "875/875 - 2s - loss: 7.1675 - 2s/epoch - 2ms/step\n",
      "Fitting Model 1, Parameters: {'desc_words': 5000, 'desc_len': 60, 'activation': 'relu', 'units layer 1': 128, 'units layer 2': 8}\n",
      "Evaluating Model 1, Parameters: {'desc_words': 5000, 'desc_len': 60, 'activation': 'relu', 'units layer 1': 128, 'units layer 2': 8}\n",
      "2624/2624 - 5s - loss: 1.9934 - 5s/epoch - 2ms/step\n",
      "875/875 - 2s - loss: 2.8290 - 2s/epoch - 2ms/step\n",
      "Fitting Model 1, Parameters: {'desc_words': 5000, 'desc_len': 60, 'activation': 'relu', 'units layer 1': 128, 'units layer 2': 16}\n",
      "Evaluating Model 1, Parameters: {'desc_words': 5000, 'desc_len': 60, 'activation': 'relu', 'units layer 1': 128, 'units layer 2': 16}\n",
      "2624/2624 - 5s - loss: 1.9098 - 5s/epoch - 2ms/step\n",
      "875/875 - 1s - loss: 2.8380 - 1s/epoch - 2ms/step\n",
      "Fitting Model 1, Parameters: {'desc_words': 5000, 'desc_len': 60, 'activation': 'relu', 'units layer 1': 128, 'units layer 2': 32}\n",
      "Evaluating Model 1, Parameters: {'desc_words': 5000, 'desc_len': 60, 'activation': 'relu', 'units layer 1': 128, 'units layer 2': 32}\n",
      "2624/2624 - 5s - loss: 732.6411 - 5s/epoch - 2ms/step\n",
      "875/875 - 2s - loss: 733.1082 - 2s/epoch - 2ms/step\n",
      "Fitting Model 1, Parameters: {'desc_words': 5000, 'desc_len': 60, 'activation': 'relu', 'units layer 1': 128, 'units layer 2': 64}\n",
      "Evaluating Model 1, Parameters: {'desc_words': 5000, 'desc_len': 60, 'activation': 'relu', 'units layer 1': 128, 'units layer 2': 64}\n",
      "2624/2624 - 5s - loss: 671.0881 - 5s/epoch - 2ms/step\n",
      "875/875 - 2s - loss: 671.2286 - 2s/epoch - 2ms/step\n",
      "Fitting Model 1, Parameters: {'desc_words': 5000, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 8, 'units layer 2': 4}\n",
      "Evaluating Model 1, Parameters: {'desc_words': 5000, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 8, 'units layer 2': 4}\n",
      "2624/2624 - 3s - loss: 9.1734 - 3s/epoch - 1ms/step\n",
      "875/875 - 1s - loss: 9.2698 - 1s/epoch - 1ms/step\n",
      "Fitting Model 1, Parameters: {'desc_words': 5000, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 8, 'units layer 2': 8}\n",
      "Evaluating Model 1, Parameters: {'desc_words': 5000, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 8, 'units layer 2': 8}\n",
      "2624/2624 - 3s - loss: 9.1736 - 3s/epoch - 1ms/step\n",
      "875/875 - 1s - loss: 9.2701 - 1s/epoch - 2ms/step\n",
      "Passing Parameters: {'desc_words': 5000, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 8, 'units layer 2': 16}\n",
      "Passing Parameters: {'desc_words': 5000, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 8, 'units layer 2': 32}\n",
      "Passing Parameters: {'desc_words': 5000, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 8, 'units layer 2': 64}\n",
      "Fitting Model 1, Parameters: {'desc_words': 5000, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 16, 'units layer 2': 4}\n",
      "Evaluating Model 1, Parameters: {'desc_words': 5000, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 16, 'units layer 2': 4}\n",
      "2624/2624 - 3s - loss: 9.1754 - 3s/epoch - 1ms/step\n",
      "875/875 - 1s - loss: 9.2720 - 1s/epoch - 2ms/step\n",
      "Fitting Model 1, Parameters: {'desc_words': 5000, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 16, 'units layer 2': 8}\n",
      "Evaluating Model 1, Parameters: {'desc_words': 5000, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 16, 'units layer 2': 8}\n",
      "2624/2624 - 3s - loss: 5.7354 - 3s/epoch - 1ms/step\n",
      "875/875 - 1s - loss: 5.8086 - 1s/epoch - 1ms/step\n",
      "Fitting Model 1, Parameters: {'desc_words': 5000, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 16, 'units layer 2': 16}\n",
      "Evaluating Model 1, Parameters: {'desc_words': 5000, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 16, 'units layer 2': 16}\n",
      "2624/2624 - 4s - loss: 2.5652 - 4s/epoch - 2ms/step\n",
      "875/875 - 1s - loss: 2.9800 - 1s/epoch - 1ms/step\n",
      "Passing Parameters: {'desc_words': 5000, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 16, 'units layer 2': 32}\n",
      "Passing Parameters: {'desc_words': 5000, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 16, 'units layer 2': 64}\n",
      "Fitting Model 1, Parameters: {'desc_words': 5000, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 32, 'units layer 2': 4}\n",
      "Evaluating Model 1, Parameters: {'desc_words': 5000, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 32, 'units layer 2': 4}\n",
      "2624/2624 - 6s - loss: 6.0004 - 6s/epoch - 2ms/step\n",
      "875/875 - 2s - loss: 6.0479 - 2s/epoch - 2ms/step\n",
      "Fitting Model 1, Parameters: {'desc_words': 5000, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 32, 'units layer 2': 8}\n",
      "Evaluating Model 1, Parameters: {'desc_words': 5000, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 32, 'units layer 2': 8}\n",
      "2624/2624 - 5s - loss: 9.1734 - 5s/epoch - 2ms/step\n",
      "875/875 - 2s - loss: 9.2698 - 2s/epoch - 2ms/step\n",
      "Fitting Model 1, Parameters: {'desc_words': 5000, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 32, 'units layer 2': 16}\n",
      "Evaluating Model 1, Parameters: {'desc_words': 5000, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 32, 'units layer 2': 16}\n",
      "2624/2624 - 4s - loss: 2.2827 - 4s/epoch - 2ms/step\n",
      "875/875 - 2s - loss: 2.6863 - 2s/epoch - 2ms/step\n",
      "Fitting Model 1, Parameters: {'desc_words': 5000, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 32, 'units layer 2': 32}\n",
      "Evaluating Model 1, Parameters: {'desc_words': 5000, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 32, 'units layer 2': 32}\n",
      "2624/2624 - 5s - loss: 9.1845 - 5s/epoch - 2ms/step\n",
      "875/875 - 1s - loss: 9.2813 - 1s/epoch - 2ms/step\n",
      "Passing Parameters: {'desc_words': 5000, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 32, 'units layer 2': 64}\n",
      "Fitting Model 1, Parameters: {'desc_words': 5000, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 64, 'units layer 2': 4}\n",
      "Evaluating Model 1, Parameters: {'desc_words': 5000, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 64, 'units layer 2': 4}\n",
      "2624/2624 - 5s - loss: 32.2810 - 5s/epoch - 2ms/step\n",
      "875/875 - 2s - loss: 32.3940 - 2s/epoch - 2ms/step\n",
      "Fitting Model 1, Parameters: {'desc_words': 5000, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 64, 'units layer 2': 8}\n",
      "Evaluating Model 1, Parameters: {'desc_words': 5000, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 64, 'units layer 2': 8}\n",
      "2624/2624 - 6s - loss: 9.1741 - 6s/epoch - 2ms/step\n",
      "875/875 - 2s - loss: 9.2706 - 2s/epoch - 2ms/step\n",
      "Fitting Model 1, Parameters: {'desc_words': 5000, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 64, 'units layer 2': 16}\n",
      "Evaluating Model 1, Parameters: {'desc_words': 5000, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 64, 'units layer 2': 16}\n",
      "2624/2624 - 5s - loss: 2.1555 - 5s/epoch - 2ms/step\n",
      "875/875 - 2s - loss: 2.5922 - 2s/epoch - 2ms/step\n",
      "Fitting Model 1, Parameters: {'desc_words': 5000, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 64, 'units layer 2': 32}\n",
      "Evaluating Model 1, Parameters: {'desc_words': 5000, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 64, 'units layer 2': 32}\n",
      "2624/2624 - 6s - loss: 2.0507 - 6s/epoch - 2ms/step\n",
      "875/875 - 2s - loss: 2.6511 - 2s/epoch - 2ms/step\n",
      "Fitting Model 1, Parameters: {'desc_words': 5000, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 64, 'units layer 2': 64}\n",
      "Evaluating Model 1, Parameters: {'desc_words': 5000, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 64, 'units layer 2': 64}\n",
      "2624/2624 - 5s - loss: 9.1793 - 5s/epoch - 2ms/step\n",
      "875/875 - 2s - loss: 9.2755 - 2s/epoch - 2ms/step\n",
      "Fitting Model 1, Parameters: {'desc_words': 5000, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 128, 'units layer 2': 4}\n",
      "Evaluating Model 1, Parameters: {'desc_words': 5000, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 128, 'units layer 2': 4}\n",
      "2624/2624 - 5s - loss: 9.1846 - 5s/epoch - 2ms/step\n",
      "875/875 - 2s - loss: 9.2814 - 2s/epoch - 2ms/step\n",
      "Fitting Model 1, Parameters: {'desc_words': 5000, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 128, 'units layer 2': 8}\n",
      "Evaluating Model 1, Parameters: {'desc_words': 5000, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 128, 'units layer 2': 8}\n",
      "2624/2624 - 5s - loss: 9.1752 - 5s/epoch - 2ms/step\n",
      "875/875 - 2s - loss: 9.2718 - 2s/epoch - 2ms/step\n",
      "Fitting Model 1, Parameters: {'desc_words': 5000, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 128, 'units layer 2': 16}\n",
      "Evaluating Model 1, Parameters: {'desc_words': 5000, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 128, 'units layer 2': 16}\n",
      "2624/2624 - 5s - loss: 4.2936 - 5s/epoch - 2ms/step\n",
      "875/875 - 2s - loss: 4.3985 - 2s/epoch - 2ms/step\n",
      "Fitting Model 1, Parameters: {'desc_words': 5000, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 128, 'units layer 2': 32}\n",
      "Evaluating Model 1, Parameters: {'desc_words': 5000, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 128, 'units layer 2': 32}\n",
      "2624/2624 - 5s - loss: 9.1751 - 5s/epoch - 2ms/step\n",
      "875/875 - 2s - loss: 9.2714 - 2s/epoch - 2ms/step\n",
      "Fitting Model 1, Parameters: {'desc_words': 5000, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 128, 'units layer 2': 64}\n",
      "Evaluating Model 1, Parameters: {'desc_words': 5000, 'desc_len': 60, 'activation': 'sigmoid', 'units layer 1': 128, 'units layer 2': 64}\n",
      "2624/2624 - 5s - loss: 1.7949 - 5s/epoch - 2ms/step\n",
      "875/875 - 2s - loss: 2.6835 - 2s/epoch - 2ms/step\n"
     ]
    }
   ],
   "source": [
    "wr_work = wine_reviews[['description','country','price','province','region_1','variety','winery','year','points']]\n",
    "wr_work.head()\n",
    "\n",
    "categorical_cols = ['country', 'province', 'region_1', 'variety', 'winery', 'year']\n",
    "numerical_cols = ['price']\n",
    "\n",
    "max_desc_len = max(wine_reviews.desc_len)\n",
    "max_desc_len\n",
    "\n",
    "tokenizer_1000 = Tokenizer(num_words=1000)\n",
    "tokenizer_1000.fit_on_texts(wr_work.description)\n",
    "desc_1000 = tokenizer_1000.texts_to_sequences(wr_work.description)\n",
    "desc_1000_max = pad_sequences(desc_1000, maxlen=max_desc_len)\n",
    "desc_1000_60 = pad_sequences(desc_1000, maxlen=60)\n",
    "desc_1000_60\n",
    "\n",
    "tokenizer_5000 = Tokenizer(num_words=5000)\n",
    "tokenizer_5000.fit_on_texts(wr_work.description)\n",
    "desc_5000 = tokenizer_5000.texts_to_sequences(wr_work.description)\n",
    "\n",
    "desc_5000_max = pad_sequences(desc_5000, maxlen=max_desc_len)\n",
    "desc_5000_60 = pad_sequences(desc_5000, maxlen=60)\n",
    "desc_5000_60\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(wr_work[categorical_cols + numerical_cols], wr_work.points, \\\n",
    "                                                    test_size = 0.25, shuffle = True, random_state = 78)\n",
    "\n",
    "\n",
    "desc_1000_max_train, desc_1000_max_test = train_test_split(desc_1000_max, test_size = 0.25, shuffle = True, random_state = 78)\n",
    "desc_1000_60_train, desc_1000_60_test = train_test_split(desc_1000_60, test_size = 0.25, shuffle = True, random_state = 78)\n",
    "desc_5000_max_train, desc_5000_max_test = train_test_split(desc_5000_max, test_size = 0.25, shuffle = True, random_state = 78)\n",
    "desc_5000_60_train, desc_5000_60_test = train_test_split(desc_5000_60, test_size = 0.25, shuffle = True, random_state = 78)\n",
    "\n",
    "desc_words = [1000, 5000]\n",
    "desc_len = [max_desc_len, 60]\n",
    "dense_activations = ['relu', 'sigmoid']\n",
    "dense_units_1 =  [8, 16, 32, 64, 128]\n",
    "dense_units_2 = [4, 8, 16, 32, 64]\n",
    "model_1_results_df = pd.DataFrame(columns = ['parameters', 'train_MSE', 'test_MSE'])\n",
    "\n",
    "for a in desc_words:\n",
    "    for b in desc_len:\n",
    "        for c in dense_activations:\n",
    "            for d in dense_units_1:\n",
    "                for e in dense_units_2:\n",
    "                    params = {'desc_words' : a, 'desc_len': b, 'activation': c,  'units layer 1': d, 'units layer 2': e}\n",
    "                    if e > d:\n",
    "                        print(f'Passing Parameters: {params}')\n",
    "                        continue  \n",
    "                    input_1 = Input(shape=(b,))\n",
    "                    embedding_1 = Embedding(input_dim = a, output_dim=10)(input_1)\n",
    "                    flatten_1 = Flatten()(embedding_1)\n",
    "                    dense_1a = Dense(units = d, activation = c)(flatten_1)\n",
    "                    drop_1 =  Dropout(0.5)(dense_1a)\n",
    "                    dense_1b = Dense(units = e, activation= c)(drop_1)\n",
    "                    output_1 = Dense(units = 1, activation= 'linear')(dense_1b)\n",
    "                    model_1 = Model(inputs=[input_1], outputs=output_1)\n",
    "\n",
    "                    model_1.compile(optimizer='adam', loss='mean_squared_error')\n",
    "                    \n",
    "                    if a == 1000 and b == max_desc_len:\n",
    "                        x_train_1, x_test_1 = desc_1000_max_train, desc_1000_max_test\n",
    "                    elif a == 1000 and b == 60:\n",
    "                        x_train_1, x_test_1 = desc_1000_60_train, desc_1000_60_test\n",
    "                    elif a == 5000 and b == max_desc_len:\n",
    "                        x_train_1, x_test_1 = desc_5000_max_train, desc_5000_max_test\n",
    "                    elif a == 5000 and b == 60:\n",
    "                        x_train_1, x_test_1 = desc_5000_60_train, desc_5000_60_test\n",
    "                        \n",
    "                    print(f'Fitting Model 1, Parameters: {params}')\n",
    "                    model_1.fit(x_train_1, y_train,\n",
    "                                batch_size=32,\n",
    "                                epochs=10,\n",
    "                                callbacks=EarlyStopping(monitor='val_loss', patience=3),\n",
    "                                workers = 8,\n",
    "                                verbose = 0,\n",
    "                        validation_data=(x_test_1, y_test))\n",
    "                    print(f'Evaluating Model 1, Parameters: {params}')\n",
    "                    train_MSE = model_1.evaluate(x_train_1, y_train, verbose = 2)\n",
    "                    test_MSE = model_1.evaluate(x_test_1, y_test, verbose = 2)\n",
    "            \n",
    "                    model_1_results_df.loc[len(model_1_results_df.index)] = ([params, train_MSE, test_MSE])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lior\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:115: DataConversionWarning:\n",
      "\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KerasTensor(type_spec=TensorSpec(shape=(None, 626, 1), dtype=tf.float32, name='input_27'), name='input_27', description=\"created by layer 'input_27'\")\n",
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"C:\\Users\\lior\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1284, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\lior\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1268, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\lior\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1249, in run_step  **\n        outputs = model.train_step(data)\n    File \"C:\\Users\\lior\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1050, in train_step\n        y_pred = self(x, training=True)\n    File \"C:\\Users\\lior\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\lior\\anaconda3\\lib\\site-packages\\keras\\engine\\input_spec.py\", line 280, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Exception encountered when calling layer 'model_19' (type Functional).\n    \n    Input 0 of layer \"dense_58\" is incompatible with the layer: expected axis -1 of input shape to have value 391876, but received input with shape (None, 626)\n    \n    Call arguments received by layer 'model_19' (type Functional):\n      • inputs=tf.Tensor(shape=(None, 1), dtype=string)\n      • training=True\n      • mask=None\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [40]\u001b[0m, in \u001b[0;36m<cell line: 24>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     45\u001b[0m                     model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39mAdam(learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m),\n\u001b[0;32m     46\u001b[0m                                   loss\u001b[38;5;241m=\u001b[39mBinaryCrossentropy(),\n\u001b[0;32m     47\u001b[0m                                   metrics\u001b[38;5;241m=\u001b[39m[Accuracy()])\n\u001b[0;32m     50\u001b[0m                     \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[1;32m---> 51\u001b[0m                     \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     52\u001b[0m \u001b[43m                              \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     53\u001b[0m \u001b[43m                              \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[43m                              \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     55\u001b[0m                     max_length\u001b[38;5;241m=\u001b[39m math\u001b[38;5;241m.\u001b[39msqrt(max_length)\n\u001b[0;32m     57\u001b[0m \u001b[38;5;66;03m# Evaluate the model\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_file9fu42n15.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(step_function), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"C:\\Users\\lior\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1284, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\lior\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1268, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\lior\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1249, in run_step  **\n        outputs = model.train_step(data)\n    File \"C:\\Users\\lior\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1050, in train_step\n        y_pred = self(x, training=True)\n    File \"C:\\Users\\lior\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\lior\\anaconda3\\lib\\site-packages\\keras\\engine\\input_spec.py\", line 280, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Exception encountered when calling layer 'model_19' (type Functional).\n    \n    Input 0 of layer \"dense_58\" is incompatible with the layer: expected axis -1 of input shape to have value 391876, but received input with shape (None, 626)\n    \n    Call arguments received by layer 'model_19' (type Functional):\n      • inputs=tf.Tensor(shape=(None, 1), dtype=string)\n      • training=True\n      • mask=None\n"
     ]
    }
   ],
   "source": [
    "max_words = [1000, 2000, 3000]\n",
    "max_len = [10, 20, 30, 40, 50, 60]\n",
    "activation_methods = ['relu', 'sigmoid','tanh']\n",
    "layer_1_dim =  [4, 8, 16, 32, 64]\n",
    "layer_2_dim = [2, 4, 8, 16, 32]\n",
    "output_dim = 16\n",
    "\n",
    "max_length=max(len(seq) for seq in wine_reviews['description']) \n",
    "\n",
    "y = pd.DataFrame(wine_reviews, columns=['points'])\n",
    "x = pd.DataFrame(wine_reviews, columns=['description'])\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.25, random_state=29)                     \n",
    "                     \n",
    "text_input_1 = Input(shape=(max_length,1))\n",
    "\n",
    "print(text_input_1)\n",
    "\n",
    "\n",
    "                     \n",
    "for m_words in max_words:\n",
    "    for m_len in max_len:\n",
    "        for l1_dim in layer_1_dim:\n",
    "            for l2_dim in layer_2_dim:\n",
    "                for act in activation_methods:  \n",
    "                    embedding_1 = Embedding(input_dim=m_len, output_dim=626)(text_input_1)\n",
    "                    tokenizer = Tokenizer(num_words=m_words)\n",
    "                    tokenizer.fit_on_texts(wine_reviews['description'])\n",
    "                    X_text1 = tokenizer.texts_to_sequences(wine_reviews['description'])\n",
    "                    X_text1 = pad_sequences(X_text1, maxlen=max_length)\n",
    "\n",
    "                    flatten_1 = Flatten()(embedding_1)\n",
    "                    \n",
    "                    x = Dense(l1_dim, activation=act)(flatten_1)\n",
    "                    x = Dense(l2_dim, activation=act)(x)\n",
    "                    output = Dense(1, activation=act)(x)\n",
    "\n",
    "                    model = Model(inputs=[text_input_1], outputs=output)\n",
    "                    \n",
    "                    plot_model(model, show_dtype=True, show_shapes=True, show_layer_names=True, to_file='model_1.png')\n",
    "\n",
    "                    model.compile(optimizer=Adam(learning_rate=0.001),\n",
    "                                  loss=BinaryCrossentropy(),\n",
    "                                  metrics=[Accuracy()])\n",
    "                    \n",
    "\n",
    "                    # Train the model\n",
    "                    model.fit(X_train, y_train,\n",
    "                              batch_size=32,\n",
    "                              epochs=10,\n",
    "                              validation_data=(X_test, y_test))\n",
    "                    max_length= math.sqrt(max_length)\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate([X_test], y_test)\n",
    "print('Test Loss:', loss)\n",
    "print('Test Accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
